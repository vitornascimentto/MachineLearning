{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('/home/matheusrmeloo/Documentos/ML/graduate-admissions/Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1                 1  \n",
       "1         1                 1  \n",
       "2         1                 1  \n",
       "3         1                 1  \n",
       "4         0                 0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['Chance of Admit '] = (data_frame['Chance of Admit '] >= .7).astype(int)\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_frame[['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research']].values.tolist()\n",
    "\n",
    "data = keras.utils.to_categorical(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data_frame[['Chance of Admit ']].values.tolist()\n",
    "\n",
    "data2 = keras.utils.to_categorical(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_frame.iloc[:,0:8]\n",
    "y = data_frame.iloc[:,8]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal', input_dim=X_train.shape[-1]))\n",
    "\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal'))\n",
    "\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 350 samples, validate on 150 samples\n",
      "Epoch 1/500\n",
      "350/350 [==============================] - 0s 677us/step - loss: 0.6954 - acc: 0.4514 - val_loss: 0.6914 - val_acc: 0.5867\n",
      "Epoch 2/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.6894 - acc: 0.6057 - val_loss: 0.6888 - val_acc: 0.5867\n",
      "Epoch 3/500\n",
      "350/350 [==============================] - 0s 113us/step - loss: 0.6823 - acc: 0.6057 - val_loss: 0.6784 - val_acc: 0.5867\n",
      "Epoch 4/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.6694 - acc: 0.6057 - val_loss: 0.6735 - val_acc: 0.5867\n",
      "Epoch 5/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.6663 - acc: 0.6057 - val_loss: 0.6734 - val_acc: 0.5867\n",
      "Epoch 6/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.6672 - acc: 0.6057 - val_loss: 0.6727 - val_acc: 0.5867\n",
      "Epoch 7/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.6654 - acc: 0.6057 - val_loss: 0.6722 - val_acc: 0.5867\n",
      "Epoch 8/500\n",
      "350/350 [==============================] - 0s 113us/step - loss: 0.6657 - acc: 0.6057 - val_loss: 0.6732 - val_acc: 0.5867\n",
      "Epoch 9/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.6656 - acc: 0.6057 - val_loss: 0.6708 - val_acc: 0.5867\n",
      "Epoch 10/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.6633 - acc: 0.6057 - val_loss: 0.6702 - val_acc: 0.5867\n",
      "Epoch 11/500\n",
      "350/350 [==============================] - 0s 113us/step - loss: 0.6627 - acc: 0.6057 - val_loss: 0.6693 - val_acc: 0.5867\n",
      "Epoch 12/500\n",
      "350/350 [==============================] - 0s 110us/step - loss: 0.6607 - acc: 0.6057 - val_loss: 0.6687 - val_acc: 0.5867\n",
      "Epoch 13/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.6598 - acc: 0.6057 - val_loss: 0.6686 - val_acc: 0.5867\n",
      "Epoch 14/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.6595 - acc: 0.6057 - val_loss: 0.6681 - val_acc: 0.5867\n",
      "Epoch 15/500\n",
      "350/350 [==============================] - 0s 115us/step - loss: 0.6568 - acc: 0.6057 - val_loss: 0.6657 - val_acc: 0.5867\n",
      "Epoch 16/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.6557 - acc: 0.6057 - val_loss: 0.6649 - val_acc: 0.5867\n",
      "Epoch 17/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.6537 - acc: 0.6057 - val_loss: 0.6642 - val_acc: 0.5867\n",
      "Epoch 18/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.6512 - acc: 0.6057 - val_loss: 0.6618 - val_acc: 0.5867\n",
      "Epoch 19/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.6491 - acc: 0.6057 - val_loss: 0.6597 - val_acc: 0.5867\n",
      "Epoch 20/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.6472 - acc: 0.6057 - val_loss: 0.6593 - val_acc: 0.5867\n",
      "Epoch 21/500\n",
      "350/350 [==============================] - 0s 184us/step - loss: 0.6478 - acc: 0.6057 - val_loss: 0.6585 - val_acc: 0.5867\n",
      "Epoch 22/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.6429 - acc: 0.6057 - val_loss: 0.6543 - val_acc: 0.5867\n",
      "Epoch 23/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.6432 - acc: 0.6057 - val_loss: 0.6535 - val_acc: 0.5867\n",
      "Epoch 24/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.6358 - acc: 0.6057 - val_loss: 0.6502 - val_acc: 0.5867\n",
      "Epoch 25/500\n",
      "350/350 [==============================] - 0s 113us/step - loss: 0.6307 - acc: 0.6057 - val_loss: 0.6473 - val_acc: 0.5867\n",
      "Epoch 26/500\n",
      "350/350 [==============================] - 0s 123us/step - loss: 0.6296 - acc: 0.6057 - val_loss: 0.6455 - val_acc: 0.5867\n",
      "Epoch 27/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.6243 - acc: 0.6057 - val_loss: 0.6423 - val_acc: 0.5867\n",
      "Epoch 28/500\n",
      "350/350 [==============================] - 0s 158us/step - loss: 0.6197 - acc: 0.6057 - val_loss: 0.6410 - val_acc: 0.5867\n",
      "Epoch 29/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.6264 - acc: 0.6143 - val_loss: 0.6394 - val_acc: 0.6267\n",
      "Epoch 30/500\n",
      "350/350 [==============================] - 0s 174us/step - loss: 0.6140 - acc: 0.6429 - val_loss: 0.6368 - val_acc: 0.6267\n",
      "Epoch 31/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.6088 - acc: 0.6686 - val_loss: 0.6363 - val_acc: 0.6200\n",
      "Epoch 32/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.6096 - acc: 0.6286 - val_loss: 0.6331 - val_acc: 0.6533\n",
      "Epoch 33/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.6038 - acc: 0.6600 - val_loss: 0.6313 - val_acc: 0.6133\n",
      "Epoch 34/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.6012 - acc: 0.6657 - val_loss: 0.6295 - val_acc: 0.6333\n",
      "Epoch 35/500\n",
      "350/350 [==============================] - 0s 148us/step - loss: 0.6041 - acc: 0.6600 - val_loss: 0.6272 - val_acc: 0.6467\n",
      "Epoch 36/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.6004 - acc: 0.6800 - val_loss: 0.6254 - val_acc: 0.6467\n",
      "Epoch 37/500\n",
      "350/350 [==============================] - 0s 117us/step - loss: 0.5953 - acc: 0.6743 - val_loss: 0.6253 - val_acc: 0.6667\n",
      "Epoch 38/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.5934 - acc: 0.6686 - val_loss: 0.6265 - val_acc: 0.6467\n",
      "Epoch 39/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.5958 - acc: 0.6714 - val_loss: 0.6187 - val_acc: 0.6600\n",
      "Epoch 40/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.5855 - acc: 0.7000 - val_loss: 0.6167 - val_acc: 0.6267\n",
      "Epoch 41/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.5809 - acc: 0.6914 - val_loss: 0.6094 - val_acc: 0.6467\n",
      "Epoch 42/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.5775 - acc: 0.7057 - val_loss: 0.6035 - val_acc: 0.6600\n",
      "Epoch 43/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.5717 - acc: 0.7086 - val_loss: 0.6049 - val_acc: 0.6533\n",
      "Epoch 44/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.5743 - acc: 0.7000 - val_loss: 0.6088 - val_acc: 0.6533\n",
      "Epoch 45/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.5679 - acc: 0.7086 - val_loss: 0.5938 - val_acc: 0.7200\n",
      "Epoch 46/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.5640 - acc: 0.7171 - val_loss: 0.5879 - val_acc: 0.6733\n",
      "Epoch 47/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.5641 - acc: 0.7371 - val_loss: 0.5849 - val_acc: 0.6533\n",
      "Epoch 48/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.5688 - acc: 0.7029 - val_loss: 0.5920 - val_acc: 0.6867\n",
      "Epoch 49/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.5558 - acc: 0.7257 - val_loss: 0.5822 - val_acc: 0.7267\n",
      "Epoch 50/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.5480 - acc: 0.7429 - val_loss: 0.5824 - val_acc: 0.6600\n",
      "Epoch 51/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.5543 - acc: 0.7200 - val_loss: 0.5682 - val_acc: 0.6867\n",
      "Epoch 52/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.5496 - acc: 0.7343 - val_loss: 0.5697 - val_acc: 0.7533\n",
      "Epoch 53/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.5391 - acc: 0.7571 - val_loss: 0.5634 - val_acc: 0.7000\n",
      "Epoch 54/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.5341 - acc: 0.7457 - val_loss: 0.5586 - val_acc: 0.7133\n",
      "Epoch 55/500\n",
      "350/350 [==============================] - 0s 101us/step - loss: 0.5324 - acc: 0.7686 - val_loss: 0.5566 - val_acc: 0.7000\n",
      "Epoch 56/500\n",
      "350/350 [==============================] - 0s 150us/step - loss: 0.5329 - acc: 0.7486 - val_loss: 0.5483 - val_acc: 0.7000\n",
      "Epoch 57/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.5268 - acc: 0.7429 - val_loss: 0.5363 - val_acc: 0.7400\n",
      "Epoch 58/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.5190 - acc: 0.7486 - val_loss: 0.5298 - val_acc: 0.7667\n",
      "Epoch 59/500\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.5202 - acc: 0.7486 - val_loss: 0.5356 - val_acc: 0.7067\n",
      "Epoch 60/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.5232 - acc: 0.7343 - val_loss: 0.5321 - val_acc: 0.7800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.5062 - acc: 0.7714 - val_loss: 0.5382 - val_acc: 0.7733\n",
      "Epoch 62/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.5153 - acc: 0.7571 - val_loss: 0.5200 - val_acc: 0.7800\n",
      "Epoch 63/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.4984 - acc: 0.7714 - val_loss: 0.5037 - val_acc: 0.7867\n",
      "Epoch 64/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.4919 - acc: 0.7657 - val_loss: 0.5015 - val_acc: 0.7533\n",
      "Epoch 65/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.4928 - acc: 0.7800 - val_loss: 0.4982 - val_acc: 0.7600\n",
      "Epoch 66/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.4767 - acc: 0.7829 - val_loss: 0.4842 - val_acc: 0.7533\n",
      "Epoch 67/500\n",
      "350/350 [==============================] - 0s 123us/step - loss: 0.4800 - acc: 0.7857 - val_loss: 0.5055 - val_acc: 0.7467\n",
      "Epoch 68/500\n",
      "350/350 [==============================] - 0s 116us/step - loss: 0.4894 - acc: 0.7657 - val_loss: 0.4922 - val_acc: 0.7667\n",
      "Epoch 69/500\n",
      "350/350 [==============================] - 0s 108us/step - loss: 0.4778 - acc: 0.7829 - val_loss: 0.4778 - val_acc: 0.7600\n",
      "Epoch 70/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.4652 - acc: 0.7914 - val_loss: 0.5068 - val_acc: 0.7533\n",
      "Epoch 71/500\n",
      "350/350 [==============================] - 0s 113us/step - loss: 0.4791 - acc: 0.7771 - val_loss: 0.4965 - val_acc: 0.7267\n",
      "Epoch 72/500\n",
      "350/350 [==============================] - 0s 119us/step - loss: 0.4561 - acc: 0.7857 - val_loss: 0.4697 - val_acc: 0.7800\n",
      "Epoch 73/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.4563 - acc: 0.7771 - val_loss: 0.5050 - val_acc: 0.7600\n",
      "Epoch 74/500\n",
      "350/350 [==============================] - 0s 148us/step - loss: 0.4665 - acc: 0.7714 - val_loss: 0.4781 - val_acc: 0.7867\n",
      "Epoch 75/500\n",
      "350/350 [==============================] - 0s 149us/step - loss: 0.4590 - acc: 0.7943 - val_loss: 0.4597 - val_acc: 0.7867\n",
      "Epoch 76/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.4448 - acc: 0.7943 - val_loss: 0.4553 - val_acc: 0.7933\n",
      "Epoch 77/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.4462 - acc: 0.7886 - val_loss: 0.4537 - val_acc: 0.8067\n",
      "Epoch 78/500\n",
      "350/350 [==============================] - 0s 110us/step - loss: 0.4462 - acc: 0.8143 - val_loss: 0.4521 - val_acc: 0.7867\n",
      "Epoch 79/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.4403 - acc: 0.8000 - val_loss: 0.4694 - val_acc: 0.7800\n",
      "Epoch 80/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.4489 - acc: 0.7914 - val_loss: 0.4757 - val_acc: 0.7733\n",
      "Epoch 81/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.4464 - acc: 0.8114 - val_loss: 0.4531 - val_acc: 0.7667\n",
      "Epoch 82/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.4526 - acc: 0.7771 - val_loss: 0.4609 - val_acc: 0.8000\n",
      "Epoch 83/500\n",
      "350/350 [==============================] - 0s 114us/step - loss: 0.4673 - acc: 0.7629 - val_loss: 0.4613 - val_acc: 0.7733\n",
      "Epoch 84/500\n",
      "350/350 [==============================] - 0s 116us/step - loss: 0.4384 - acc: 0.7943 - val_loss: 0.4434 - val_acc: 0.8000\n",
      "Epoch 85/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.4365 - acc: 0.7914 - val_loss: 0.4871 - val_acc: 0.7533\n",
      "Epoch 86/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.4388 - acc: 0.8057 - val_loss: 0.4422 - val_acc: 0.7733\n",
      "Epoch 87/500\n",
      "350/350 [==============================] - 0s 174us/step - loss: 0.4312 - acc: 0.7943 - val_loss: 0.4414 - val_acc: 0.7867\n",
      "Epoch 88/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.4389 - acc: 0.7943 - val_loss: 0.4515 - val_acc: 0.7667\n",
      "Epoch 89/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.4365 - acc: 0.7886 - val_loss: 0.4548 - val_acc: 0.7867\n",
      "Epoch 90/500\n",
      "350/350 [==============================] - 0s 151us/step - loss: 0.4417 - acc: 0.8086 - val_loss: 0.4415 - val_acc: 0.7800\n",
      "Epoch 91/500\n",
      "350/350 [==============================] - 0s 119us/step - loss: 0.4313 - acc: 0.8171 - val_loss: 0.4414 - val_acc: 0.7933\n",
      "Epoch 92/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.4263 - acc: 0.8029 - val_loss: 0.4479 - val_acc: 0.8067\n",
      "Epoch 93/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.4258 - acc: 0.8000 - val_loss: 0.4392 - val_acc: 0.7933\n",
      "Epoch 94/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.4215 - acc: 0.7943 - val_loss: 0.4514 - val_acc: 0.7733\n",
      "Epoch 95/500\n",
      "350/350 [==============================] - 0s 151us/step - loss: 0.4292 - acc: 0.8000 - val_loss: 0.4339 - val_acc: 0.7933\n",
      "Epoch 96/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.4307 - acc: 0.7829 - val_loss: 0.4457 - val_acc: 0.8000\n",
      "Epoch 97/500\n",
      "350/350 [==============================] - 0s 117us/step - loss: 0.4461 - acc: 0.8114 - val_loss: 0.4457 - val_acc: 0.7733\n",
      "Epoch 98/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.4218 - acc: 0.8000 - val_loss: 0.4368 - val_acc: 0.7800\n",
      "Epoch 99/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.4210 - acc: 0.8057 - val_loss: 0.4451 - val_acc: 0.7667\n",
      "Epoch 100/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.4413 - acc: 0.8000 - val_loss: 0.4469 - val_acc: 0.7867\n",
      "Epoch 101/500\n",
      "350/350 [==============================] - 0s 185us/step - loss: 0.4255 - acc: 0.7800 - val_loss: 0.4439 - val_acc: 0.7733\n",
      "Epoch 102/500\n",
      "350/350 [==============================] - 0s 161us/step - loss: 0.4313 - acc: 0.7914 - val_loss: 0.4545 - val_acc: 0.7667\n",
      "Epoch 103/500\n",
      "350/350 [==============================] - 0s 119us/step - loss: 0.4247 - acc: 0.8000 - val_loss: 0.4475 - val_acc: 0.7733\n",
      "Epoch 104/500\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.4116 - acc: 0.8114 - val_loss: 0.4496 - val_acc: 0.7800\n",
      "Epoch 105/500\n",
      "350/350 [==============================] - 0s 113us/step - loss: 0.4409 - acc: 0.7886 - val_loss: 0.4479 - val_acc: 0.7733\n",
      "Epoch 106/500\n",
      "350/350 [==============================] - 0s 152us/step - loss: 0.4112 - acc: 0.8200 - val_loss: 0.4372 - val_acc: 0.7867\n",
      "Epoch 107/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.4318 - acc: 0.7886 - val_loss: 0.4447 - val_acc: 0.7933\n",
      "Epoch 108/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.4422 - acc: 0.7886 - val_loss: 0.4421 - val_acc: 0.7800\n",
      "Epoch 109/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.4297 - acc: 0.7971 - val_loss: 0.4332 - val_acc: 0.7800\n",
      "Epoch 110/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.4153 - acc: 0.8000 - val_loss: 0.4318 - val_acc: 0.7933\n",
      "Epoch 111/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.4150 - acc: 0.8143 - val_loss: 0.4285 - val_acc: 0.7867\n",
      "Epoch 112/500\n",
      "350/350 [==============================] - 0s 166us/step - loss: 0.4191 - acc: 0.8086 - val_loss: 0.4342 - val_acc: 0.7867\n",
      "Epoch 113/500\n",
      "350/350 [==============================] - 0s 168us/step - loss: 0.4172 - acc: 0.8200 - val_loss: 0.4286 - val_acc: 0.7800\n",
      "Epoch 114/500\n",
      "350/350 [==============================] - 0s 151us/step - loss: 0.4133 - acc: 0.8143 - val_loss: 0.4317 - val_acc: 0.7800\n",
      "Epoch 115/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.4327 - acc: 0.8000 - val_loss: 0.4610 - val_acc: 0.7933\n",
      "Epoch 116/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.4203 - acc: 0.8086 - val_loss: 0.4335 - val_acc: 0.7933\n",
      "Epoch 117/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.4193 - acc: 0.7800 - val_loss: 0.4585 - val_acc: 0.7800\n",
      "Epoch 118/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.4335 - acc: 0.7943 - val_loss: 0.4328 - val_acc: 0.7800\n",
      "Epoch 119/500\n",
      "350/350 [==============================] - 0s 119us/step - loss: 0.4095 - acc: 0.8086 - val_loss: 0.4327 - val_acc: 0.7733\n",
      "Epoch 120/500\n",
      "350/350 [==============================] - 0s 119us/step - loss: 0.4143 - acc: 0.8086 - val_loss: 0.4284 - val_acc: 0.7867\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 139us/step - loss: 0.4164 - acc: 0.7971 - val_loss: 0.4287 - val_acc: 0.7933\n",
      "Epoch 122/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.4150 - acc: 0.8057 - val_loss: 0.4250 - val_acc: 0.7933\n",
      "Epoch 123/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.4185 - acc: 0.8143 - val_loss: 0.4272 - val_acc: 0.7800\n",
      "Epoch 124/500\n",
      "350/350 [==============================] - 0s 109us/step - loss: 0.4104 - acc: 0.8029 - val_loss: 0.4293 - val_acc: 0.7733\n",
      "Epoch 125/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.4144 - acc: 0.8114 - val_loss: 0.4284 - val_acc: 0.7800\n",
      "Epoch 126/500\n",
      "350/350 [==============================] - 0s 110us/step - loss: 0.4018 - acc: 0.8143 - val_loss: 0.4618 - val_acc: 0.7733\n",
      "Epoch 127/500\n",
      "350/350 [==============================] - 0s 103us/step - loss: 0.4157 - acc: 0.7971 - val_loss: 0.4657 - val_acc: 0.7800\n",
      "Epoch 128/500\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.4090 - acc: 0.8171 - val_loss: 0.4289 - val_acc: 0.7800\n",
      "Epoch 129/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.4120 - acc: 0.8200 - val_loss: 0.4257 - val_acc: 0.7733\n",
      "Epoch 130/500\n",
      "350/350 [==============================] - 0s 119us/step - loss: 0.4111 - acc: 0.8171 - val_loss: 0.4456 - val_acc: 0.7800\n",
      "Epoch 131/500\n",
      "350/350 [==============================] - 0s 117us/step - loss: 0.4180 - acc: 0.8000 - val_loss: 0.4263 - val_acc: 0.7667\n",
      "Epoch 132/500\n",
      "350/350 [==============================] - 0s 123us/step - loss: 0.4147 - acc: 0.8029 - val_loss: 0.4312 - val_acc: 0.7800\n",
      "Epoch 133/500\n",
      "350/350 [==============================] - 0s 186us/step - loss: 0.4109 - acc: 0.8143 - val_loss: 0.4253 - val_acc: 0.7867\n",
      "Epoch 134/500\n",
      "350/350 [==============================] - 0s 176us/step - loss: 0.4151 - acc: 0.8029 - val_loss: 0.4276 - val_acc: 0.7667\n",
      "Epoch 135/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.4111 - acc: 0.8029 - val_loss: 0.5118 - val_acc: 0.7267\n",
      "Epoch 136/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.4352 - acc: 0.7886 - val_loss: 0.4347 - val_acc: 0.7667\n",
      "Epoch 137/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.4042 - acc: 0.8086 - val_loss: 0.4232 - val_acc: 0.7867\n",
      "Epoch 138/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.4002 - acc: 0.8114 - val_loss: 0.4263 - val_acc: 0.7733\n",
      "Epoch 139/500\n",
      "350/350 [==============================] - 0s 113us/step - loss: 0.4048 - acc: 0.8257 - val_loss: 0.4360 - val_acc: 0.7867\n",
      "Epoch 140/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.4140 - acc: 0.8171 - val_loss: 0.4260 - val_acc: 0.7733\n",
      "Epoch 141/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.4051 - acc: 0.8057 - val_loss: 0.4220 - val_acc: 0.7867\n",
      "Epoch 142/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.4081 - acc: 0.7971 - val_loss: 0.4226 - val_acc: 0.7933\n",
      "Epoch 143/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.4123 - acc: 0.8086 - val_loss: 0.4245 - val_acc: 0.7867\n",
      "Epoch 144/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.4044 - acc: 0.8257 - val_loss: 0.4276 - val_acc: 0.7667\n",
      "Epoch 145/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.4108 - acc: 0.7829 - val_loss: 0.4518 - val_acc: 0.7867\n",
      "Epoch 146/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.4125 - acc: 0.8143 - val_loss: 0.4327 - val_acc: 0.7800\n",
      "Epoch 147/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.4059 - acc: 0.8143 - val_loss: 0.4350 - val_acc: 0.7933\n",
      "Epoch 148/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.4002 - acc: 0.8314 - val_loss: 0.4331 - val_acc: 0.7667\n",
      "Epoch 149/500\n",
      "350/350 [==============================] - 0s 101us/step - loss: 0.4155 - acc: 0.8029 - val_loss: 0.4239 - val_acc: 0.7800\n",
      "Epoch 150/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.4161 - acc: 0.7943 - val_loss: 0.4226 - val_acc: 0.7800\n",
      "Epoch 151/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.4252 - acc: 0.8086 - val_loss: 0.4298 - val_acc: 0.7733\n",
      "Epoch 152/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.4059 - acc: 0.8171 - val_loss: 0.4218 - val_acc: 0.7867\n",
      "Epoch 153/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.4031 - acc: 0.8114 - val_loss: 0.4212 - val_acc: 0.7867\n",
      "Epoch 154/500\n",
      "350/350 [==============================] - 0s 114us/step - loss: 0.4048 - acc: 0.8143 - val_loss: 0.4228 - val_acc: 0.7933\n",
      "Epoch 155/500\n",
      "350/350 [==============================] - 0s 116us/step - loss: 0.4059 - acc: 0.8171 - val_loss: 0.4222 - val_acc: 0.7867\n",
      "Epoch 156/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.4076 - acc: 0.8143 - val_loss: 0.4218 - val_acc: 0.7867\n",
      "Epoch 157/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.4020 - acc: 0.8029 - val_loss: 0.4205 - val_acc: 0.7867\n",
      "Epoch 158/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.4045 - acc: 0.8000 - val_loss: 0.4213 - val_acc: 0.7800\n",
      "Epoch 159/500\n",
      "350/350 [==============================] - 0s 119us/step - loss: 0.4086 - acc: 0.8057 - val_loss: 0.4891 - val_acc: 0.7600\n",
      "Epoch 160/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.4190 - acc: 0.8143 - val_loss: 0.4403 - val_acc: 0.7933\n",
      "Epoch 161/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.4069 - acc: 0.8029 - val_loss: 0.4409 - val_acc: 0.7933\n",
      "Epoch 162/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.4030 - acc: 0.8171 - val_loss: 0.4290 - val_acc: 0.7800\n",
      "Epoch 163/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.4072 - acc: 0.8171 - val_loss: 0.4282 - val_acc: 0.7800\n",
      "Epoch 164/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.4024 - acc: 0.8200 - val_loss: 0.4214 - val_acc: 0.7933\n",
      "Epoch 165/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.4015 - acc: 0.8086 - val_loss: 0.4278 - val_acc: 0.7733\n",
      "Epoch 166/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.4010 - acc: 0.8229 - val_loss: 0.4207 - val_acc: 0.7800\n",
      "Epoch 167/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.4017 - acc: 0.8171 - val_loss: 0.4247 - val_acc: 0.7800\n",
      "Epoch 168/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.4021 - acc: 0.8171 - val_loss: 0.4190 - val_acc: 0.7933\n",
      "Epoch 169/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.3981 - acc: 0.8114 - val_loss: 0.4197 - val_acc: 0.7867\n",
      "Epoch 170/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.3942 - acc: 0.8171 - val_loss: 0.4200 - val_acc: 0.7800\n",
      "Epoch 171/500\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.3937 - acc: 0.8229 - val_loss: 0.4261 - val_acc: 0.7867\n",
      "Epoch 172/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.4111 - acc: 0.7943 - val_loss: 0.4354 - val_acc: 0.7867\n",
      "Epoch 173/500\n",
      "350/350 [==============================] - 0s 123us/step - loss: 0.4013 - acc: 0.8229 - val_loss: 0.4205 - val_acc: 0.7867\n",
      "Epoch 174/500\n",
      "350/350 [==============================] - 0s 171us/step - loss: 0.4012 - acc: 0.8171 - val_loss: 0.4294 - val_acc: 0.7733\n",
      "Epoch 175/500\n",
      "350/350 [==============================] - 0s 212us/step - loss: 0.3981 - acc: 0.8057 - val_loss: 0.4192 - val_acc: 0.8000\n",
      "Epoch 176/500\n",
      "350/350 [==============================] - 0s 171us/step - loss: 0.4039 - acc: 0.8000 - val_loss: 0.4436 - val_acc: 0.7867\n",
      "Epoch 177/500\n",
      "350/350 [==============================] - 0s 169us/step - loss: 0.4038 - acc: 0.8057 - val_loss: 0.4240 - val_acc: 0.7800\n",
      "Epoch 178/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.3998 - acc: 0.8086 - val_loss: 0.4210 - val_acc: 0.7867\n",
      "Epoch 179/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.4122 - acc: 0.8086 - val_loss: 0.4318 - val_acc: 0.7933\n",
      "Epoch 180/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3994 - acc: 0.8200 - val_loss: 0.4173 - val_acc: 0.7933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "350/350 [==============================] - 0s 158us/step - loss: 0.3963 - acc: 0.8200 - val_loss: 0.4195 - val_acc: 0.7733\n",
      "Epoch 182/500\n",
      "350/350 [==============================] - 0s 119us/step - loss: 0.3973 - acc: 0.8171 - val_loss: 0.4251 - val_acc: 0.7800\n",
      "Epoch 183/500\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.4070 - acc: 0.8286 - val_loss: 0.4198 - val_acc: 0.7867\n",
      "Epoch 184/500\n",
      "350/350 [==============================] - 0s 123us/step - loss: 0.3936 - acc: 0.8143 - val_loss: 0.4166 - val_acc: 0.7933\n",
      "Epoch 185/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.4019 - acc: 0.8229 - val_loss: 0.4273 - val_acc: 0.7800\n",
      "Epoch 186/500\n",
      "350/350 [==============================] - 0s 116us/step - loss: 0.4059 - acc: 0.8114 - val_loss: 0.4160 - val_acc: 0.7933\n",
      "Epoch 187/500\n",
      "350/350 [==============================] - 0s 104us/step - loss: 0.4051 - acc: 0.8114 - val_loss: 0.4166 - val_acc: 0.7933\n",
      "Epoch 188/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.4085 - acc: 0.8314 - val_loss: 0.4285 - val_acc: 0.7933\n",
      "Epoch 189/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.3968 - acc: 0.8200 - val_loss: 0.4290 - val_acc: 0.7800\n",
      "Epoch 190/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.3956 - acc: 0.8086 - val_loss: 0.4331 - val_acc: 0.7800\n",
      "Epoch 191/500\n",
      "350/350 [==============================] - 0s 117us/step - loss: 0.3997 - acc: 0.8086 - val_loss: 0.4339 - val_acc: 0.7933\n",
      "Epoch 192/500\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.3992 - acc: 0.8257 - val_loss: 0.4404 - val_acc: 0.7933\n",
      "Epoch 193/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.3941 - acc: 0.8229 - val_loss: 0.4229 - val_acc: 0.7800\n",
      "Epoch 194/500\n",
      "350/350 [==============================] - 0s 104us/step - loss: 0.3944 - acc: 0.8314 - val_loss: 0.4176 - val_acc: 0.8000\n",
      "Epoch 195/500\n",
      "350/350 [==============================] - 0s 123us/step - loss: 0.4027 - acc: 0.8286 - val_loss: 0.4193 - val_acc: 0.7800\n",
      "Epoch 196/500\n",
      "350/350 [==============================] - 0s 109us/step - loss: 0.4034 - acc: 0.8029 - val_loss: 0.4190 - val_acc: 0.8000\n",
      "Epoch 197/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.3986 - acc: 0.8257 - val_loss: 0.4224 - val_acc: 0.7933\n",
      "Epoch 198/500\n",
      "350/350 [==============================] - 0s 108us/step - loss: 0.4105 - acc: 0.8086 - val_loss: 0.4227 - val_acc: 0.7800\n",
      "Epoch 199/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.4059 - acc: 0.8143 - val_loss: 0.4191 - val_acc: 0.7867\n",
      "Epoch 200/500\n",
      "350/350 [==============================] - 0s 113us/step - loss: 0.3964 - acc: 0.8229 - val_loss: 0.4177 - val_acc: 0.7933\n",
      "Epoch 201/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.3978 - acc: 0.8200 - val_loss: 0.4164 - val_acc: 0.7933\n",
      "Epoch 202/500\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.4011 - acc: 0.8143 - val_loss: 0.4354 - val_acc: 0.7867\n",
      "Epoch 203/500\n",
      "350/350 [==============================] - 0s 104us/step - loss: 0.4009 - acc: 0.8171 - val_loss: 0.4230 - val_acc: 0.7867\n",
      "Epoch 204/500\n",
      "350/350 [==============================] - 0s 109us/step - loss: 0.3893 - acc: 0.8229 - val_loss: 0.4194 - val_acc: 0.7800\n",
      "Epoch 205/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3925 - acc: 0.8114 - val_loss: 0.4212 - val_acc: 0.7867\n",
      "Epoch 206/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.3989 - acc: 0.8200 - val_loss: 0.4280 - val_acc: 0.7733\n",
      "Epoch 207/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.3975 - acc: 0.8200 - val_loss: 0.4512 - val_acc: 0.7867\n",
      "Epoch 208/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.3926 - acc: 0.8257 - val_loss: 0.4204 - val_acc: 0.7867\n",
      "Epoch 209/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3948 - acc: 0.8286 - val_loss: 0.4175 - val_acc: 0.7933\n",
      "Epoch 210/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.3916 - acc: 0.8171 - val_loss: 0.4184 - val_acc: 0.8000\n",
      "Epoch 211/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.3889 - acc: 0.8143 - val_loss: 0.4154 - val_acc: 0.8067\n",
      "Epoch 212/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.4046 - acc: 0.8029 - val_loss: 0.4182 - val_acc: 0.8000\n",
      "Epoch 213/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.3931 - acc: 0.8171 - val_loss: 0.4193 - val_acc: 0.7933\n",
      "Epoch 214/500\n",
      "350/350 [==============================] - 0s 116us/step - loss: 0.3866 - acc: 0.8314 - val_loss: 0.4190 - val_acc: 0.8000\n",
      "Epoch 215/500\n",
      "350/350 [==============================] - 0s 108us/step - loss: 0.3892 - acc: 0.8257 - val_loss: 0.4208 - val_acc: 0.8067\n",
      "Epoch 216/500\n",
      "350/350 [==============================] - 0s 110us/step - loss: 0.3905 - acc: 0.8114 - val_loss: 0.4224 - val_acc: 0.8133\n",
      "Epoch 217/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3955 - acc: 0.8143 - val_loss: 0.4255 - val_acc: 0.8133\n",
      "Epoch 218/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.3959 - acc: 0.8314 - val_loss: 0.4253 - val_acc: 0.7933\n",
      "Epoch 219/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.3852 - acc: 0.8257 - val_loss: 0.4373 - val_acc: 0.7867\n",
      "Epoch 220/500\n",
      "350/350 [==============================] - 0s 148us/step - loss: 0.3858 - acc: 0.8229 - val_loss: 0.4342 - val_acc: 0.8000\n",
      "Epoch 221/500\n",
      "350/350 [==============================] - 0s 176us/step - loss: 0.3822 - acc: 0.8143 - val_loss: 0.4221 - val_acc: 0.7933\n",
      "Epoch 222/500\n",
      "350/350 [==============================] - 0s 163us/step - loss: 0.3985 - acc: 0.8286 - val_loss: 0.4281 - val_acc: 0.7933\n",
      "Epoch 223/500\n",
      "350/350 [==============================] - 0s 170us/step - loss: 0.3846 - acc: 0.8286 - val_loss: 0.4205 - val_acc: 0.7933\n",
      "Epoch 224/500\n",
      "350/350 [==============================] - 0s 104us/step - loss: 0.3857 - acc: 0.8457 - val_loss: 0.4213 - val_acc: 0.7867\n",
      "Epoch 225/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3856 - acc: 0.8200 - val_loss: 0.4238 - val_acc: 0.7933\n",
      "Epoch 226/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.3959 - acc: 0.8229 - val_loss: 0.4224 - val_acc: 0.7800\n",
      "Epoch 227/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3822 - acc: 0.8286 - val_loss: 0.4198 - val_acc: 0.8000\n",
      "Epoch 228/500\n",
      "350/350 [==============================] - 0s 116us/step - loss: 0.3830 - acc: 0.8171 - val_loss: 0.4180 - val_acc: 0.8067\n",
      "Epoch 229/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3995 - acc: 0.8057 - val_loss: 0.4478 - val_acc: 0.7667\n",
      "Epoch 230/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3910 - acc: 0.8257 - val_loss: 0.4267 - val_acc: 0.8000\n",
      "Epoch 231/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.3874 - acc: 0.8229 - val_loss: 0.4313 - val_acc: 0.7867\n",
      "Epoch 232/500\n",
      "350/350 [==============================] - 0s 98us/step - loss: 0.3971 - acc: 0.8200 - val_loss: 0.4459 - val_acc: 0.7933\n",
      "Epoch 233/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3783 - acc: 0.8429 - val_loss: 0.4207 - val_acc: 0.8000\n",
      "Epoch 234/500\n",
      "350/350 [==============================] - 0s 102us/step - loss: 0.3823 - acc: 0.8171 - val_loss: 0.4200 - val_acc: 0.7933\n",
      "Epoch 235/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3784 - acc: 0.8286 - val_loss: 0.4177 - val_acc: 0.8067\n",
      "Epoch 236/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3860 - acc: 0.8200 - val_loss: 0.4208 - val_acc: 0.7933\n",
      "Epoch 237/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3814 - acc: 0.8343 - val_loss: 0.4172 - val_acc: 0.8067\n",
      "Epoch 238/500\n",
      "350/350 [==============================] - 0s 89us/step - loss: 0.3794 - acc: 0.8314 - val_loss: 0.4605 - val_acc: 0.8000\n",
      "Epoch 239/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3872 - acc: 0.8371 - val_loss: 0.4445 - val_acc: 0.7867\n",
      "Epoch 240/500\n",
      "350/350 [==============================] - 0s 101us/step - loss: 0.3838 - acc: 0.8343 - val_loss: 0.4183 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3841 - acc: 0.8343 - val_loss: 0.4469 - val_acc: 0.7867\n",
      "Epoch 242/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3821 - acc: 0.8229 - val_loss: 0.4467 - val_acc: 0.7867\n",
      "Epoch 243/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3834 - acc: 0.8343 - val_loss: 0.4334 - val_acc: 0.7867\n",
      "Epoch 244/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3832 - acc: 0.8400 - val_loss: 0.4167 - val_acc: 0.8000\n",
      "Epoch 245/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3815 - acc: 0.8114 - val_loss: 0.4178 - val_acc: 0.7933\n",
      "Epoch 246/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3921 - acc: 0.8371 - val_loss: 0.4180 - val_acc: 0.8133\n",
      "Epoch 247/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.4009 - acc: 0.8429 - val_loss: 0.4250 - val_acc: 0.7933\n",
      "Epoch 248/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3803 - acc: 0.8286 - val_loss: 0.4194 - val_acc: 0.7933\n",
      "Epoch 249/500\n",
      "350/350 [==============================] - 0s 89us/step - loss: 0.3876 - acc: 0.8171 - val_loss: 0.4179 - val_acc: 0.7933\n",
      "Epoch 250/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3819 - acc: 0.8343 - val_loss: 0.4173 - val_acc: 0.7933\n",
      "Epoch 251/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3978 - acc: 0.8257 - val_loss: 0.4230 - val_acc: 0.8000\n",
      "Epoch 252/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.4138 - acc: 0.8086 - val_loss: 0.4480 - val_acc: 0.7867\n",
      "Epoch 253/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3886 - acc: 0.8286 - val_loss: 0.4268 - val_acc: 0.8000\n",
      "Epoch 254/500\n",
      "350/350 [==============================] - 0s 89us/step - loss: 0.3850 - acc: 0.8343 - val_loss: 0.4314 - val_acc: 0.8000\n",
      "Epoch 255/500\n",
      "350/350 [==============================] - 0s 98us/step - loss: 0.3853 - acc: 0.8429 - val_loss: 0.4174 - val_acc: 0.7867\n",
      "Epoch 256/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3889 - acc: 0.8229 - val_loss: 0.4162 - val_acc: 0.8067\n",
      "Epoch 257/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3806 - acc: 0.8257 - val_loss: 0.4245 - val_acc: 0.7867\n",
      "Epoch 258/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3804 - acc: 0.8400 - val_loss: 0.4156 - val_acc: 0.8133\n",
      "Epoch 259/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.3831 - acc: 0.8257 - val_loss: 0.4191 - val_acc: 0.8067\n",
      "Epoch 260/500\n",
      "350/350 [==============================] - 0s 115us/step - loss: 0.3881 - acc: 0.8257 - val_loss: 0.4172 - val_acc: 0.7933\n",
      "Epoch 261/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3845 - acc: 0.8286 - val_loss: 0.4214 - val_acc: 0.7867\n",
      "Epoch 262/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3917 - acc: 0.8143 - val_loss: 0.4203 - val_acc: 0.7867\n",
      "Epoch 263/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3872 - acc: 0.8257 - val_loss: 0.4256 - val_acc: 0.7933\n",
      "Epoch 264/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3772 - acc: 0.8343 - val_loss: 0.4564 - val_acc: 0.8000\n",
      "Epoch 265/500\n",
      "350/350 [==============================] - 0s 102us/step - loss: 0.4037 - acc: 0.8200 - val_loss: 0.4261 - val_acc: 0.7933\n",
      "Epoch 266/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3748 - acc: 0.8229 - val_loss: 0.4235 - val_acc: 0.8067\n",
      "Epoch 267/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3777 - acc: 0.8229 - val_loss: 0.4261 - val_acc: 0.7933\n",
      "Epoch 268/500\n",
      "350/350 [==============================] - 0s 98us/step - loss: 0.3775 - acc: 0.8400 - val_loss: 0.4211 - val_acc: 0.7800\n",
      "Epoch 269/500\n",
      "350/350 [==============================] - 0s 158us/step - loss: 0.3843 - acc: 0.8257 - val_loss: 0.4333 - val_acc: 0.7867\n",
      "Epoch 270/500\n",
      "350/350 [==============================] - 0s 113us/step - loss: 0.3777 - acc: 0.8400 - val_loss: 0.4157 - val_acc: 0.7933\n",
      "Epoch 271/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3838 - acc: 0.8343 - val_loss: 0.4177 - val_acc: 0.8133\n",
      "Epoch 272/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3718 - acc: 0.8314 - val_loss: 0.4257 - val_acc: 0.7933\n",
      "Epoch 273/500\n",
      "350/350 [==============================] - 0s 102us/step - loss: 0.3769 - acc: 0.8343 - val_loss: 0.4672 - val_acc: 0.8000\n",
      "Epoch 274/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3798 - acc: 0.8457 - val_loss: 0.4152 - val_acc: 0.8133\n",
      "Epoch 275/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3799 - acc: 0.8229 - val_loss: 0.4178 - val_acc: 0.8000\n",
      "Epoch 276/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3791 - acc: 0.8429 - val_loss: 0.4194 - val_acc: 0.7800\n",
      "Epoch 277/500\n",
      "350/350 [==============================] - 0s 101us/step - loss: 0.3720 - acc: 0.8257 - val_loss: 0.4298 - val_acc: 0.7933\n",
      "Epoch 278/500\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.3973 - acc: 0.8457 - val_loss: 0.4594 - val_acc: 0.7867\n",
      "Epoch 279/500\n",
      "350/350 [==============================] - 0s 109us/step - loss: 0.3821 - acc: 0.8229 - val_loss: 0.4763 - val_acc: 0.8000\n",
      "Epoch 280/500\n",
      "350/350 [==============================] - 0s 106us/step - loss: 0.4006 - acc: 0.8114 - val_loss: 0.4132 - val_acc: 0.8067\n",
      "Epoch 281/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.3754 - acc: 0.8343 - val_loss: 0.4153 - val_acc: 0.8000\n",
      "Epoch 282/500\n",
      "350/350 [==============================] - 0s 103us/step - loss: 0.3848 - acc: 0.8286 - val_loss: 0.4317 - val_acc: 0.7867\n",
      "Epoch 283/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3882 - acc: 0.8257 - val_loss: 0.4170 - val_acc: 0.7933\n",
      "Epoch 284/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3828 - acc: 0.8371 - val_loss: 0.4212 - val_acc: 0.8067\n",
      "Epoch 285/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3751 - acc: 0.8343 - val_loss: 0.4259 - val_acc: 0.7933\n",
      "Epoch 286/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3738 - acc: 0.8457 - val_loss: 0.4156 - val_acc: 0.8133\n",
      "Epoch 287/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3967 - acc: 0.8057 - val_loss: 0.4187 - val_acc: 0.8067\n",
      "Epoch 288/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3929 - acc: 0.8200 - val_loss: 0.4146 - val_acc: 0.7933\n",
      "Epoch 289/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3733 - acc: 0.8257 - val_loss: 0.4141 - val_acc: 0.7933\n",
      "Epoch 290/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3787 - acc: 0.8457 - val_loss: 0.4495 - val_acc: 0.7867\n",
      "Epoch 291/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3808 - acc: 0.8429 - val_loss: 0.4239 - val_acc: 0.8000\n",
      "Epoch 292/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3794 - acc: 0.8429 - val_loss: 0.4155 - val_acc: 0.8000\n",
      "Epoch 293/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3811 - acc: 0.8314 - val_loss: 0.4596 - val_acc: 0.7867\n",
      "Epoch 294/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3786 - acc: 0.8286 - val_loss: 0.4255 - val_acc: 0.7867\n",
      "Epoch 295/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3884 - acc: 0.8257 - val_loss: 0.4261 - val_acc: 0.8000\n",
      "Epoch 296/500\n",
      "350/350 [==============================] - 0s 101us/step - loss: 0.3898 - acc: 0.8257 - val_loss: 0.4228 - val_acc: 0.8067\n",
      "Epoch 297/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3838 - acc: 0.8457 - val_loss: 0.4245 - val_acc: 0.7933\n",
      "Epoch 298/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3775 - acc: 0.8286 - val_loss: 0.4152 - val_acc: 0.8067\n",
      "Epoch 299/500\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.3721 - acc: 0.8371 - val_loss: 0.4192 - val_acc: 0.8067\n",
      "Epoch 300/500\n",
      "350/350 [==============================] - 0s 98us/step - loss: 0.3747 - acc: 0.8257 - val_loss: 0.4150 - val_acc: 0.8000\n",
      "Epoch 301/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 104us/step - loss: 0.3789 - acc: 0.8400 - val_loss: 0.4264 - val_acc: 0.7933\n",
      "Epoch 302/500\n",
      "350/350 [==============================] - 0s 102us/step - loss: 0.3777 - acc: 0.8371 - val_loss: 0.4142 - val_acc: 0.8067\n",
      "Epoch 303/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3802 - acc: 0.8257 - val_loss: 0.4150 - val_acc: 0.7933\n",
      "Epoch 304/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3748 - acc: 0.8486 - val_loss: 0.4149 - val_acc: 0.8200\n",
      "Epoch 305/500\n",
      "350/350 [==============================] - 0s 108us/step - loss: 0.3748 - acc: 0.8286 - val_loss: 0.4140 - val_acc: 0.8067\n",
      "Epoch 306/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3786 - acc: 0.8343 - val_loss: 0.4151 - val_acc: 0.8067\n",
      "Epoch 307/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.3814 - acc: 0.8343 - val_loss: 0.4197 - val_acc: 0.8067\n",
      "Epoch 308/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.3747 - acc: 0.8257 - val_loss: 0.4440 - val_acc: 0.7867\n",
      "Epoch 309/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3782 - acc: 0.8400 - val_loss: 0.4137 - val_acc: 0.8000\n",
      "Epoch 310/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3731 - acc: 0.8343 - val_loss: 0.4302 - val_acc: 0.7867\n",
      "Epoch 311/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3879 - acc: 0.8371 - val_loss: 0.4638 - val_acc: 0.7867\n",
      "Epoch 312/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3756 - acc: 0.8371 - val_loss: 0.4158 - val_acc: 0.8067\n",
      "Epoch 313/500\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.3763 - acc: 0.8314 - val_loss: 0.4267 - val_acc: 0.7867\n",
      "Epoch 314/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3794 - acc: 0.8229 - val_loss: 0.4237 - val_acc: 0.7933\n",
      "Epoch 315/500\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.3754 - acc: 0.8314 - val_loss: 0.4144 - val_acc: 0.7933\n",
      "Epoch 316/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3697 - acc: 0.8400 - val_loss: 0.4184 - val_acc: 0.8000\n",
      "Epoch 317/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3808 - acc: 0.8200 - val_loss: 0.4431 - val_acc: 0.7867\n",
      "Epoch 318/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3962 - acc: 0.8229 - val_loss: 0.4302 - val_acc: 0.7933\n",
      "Epoch 319/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3765 - acc: 0.8200 - val_loss: 0.4191 - val_acc: 0.8000\n",
      "Epoch 320/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3743 - acc: 0.8400 - val_loss: 0.4334 - val_acc: 0.7867\n",
      "Epoch 321/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3768 - acc: 0.8257 - val_loss: 0.4152 - val_acc: 0.8000\n",
      "Epoch 322/500\n",
      "350/350 [==============================] - 0s 103us/step - loss: 0.3814 - acc: 0.8257 - val_loss: 0.4144 - val_acc: 0.7933\n",
      "Epoch 323/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3763 - acc: 0.8314 - val_loss: 0.4143 - val_acc: 0.8000\n",
      "Epoch 324/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.3772 - acc: 0.8343 - val_loss: 0.4120 - val_acc: 0.8067\n",
      "Epoch 325/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3730 - acc: 0.8286 - val_loss: 0.4155 - val_acc: 0.7800\n",
      "Epoch 326/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3873 - acc: 0.8371 - val_loss: 0.4260 - val_acc: 0.8000\n",
      "Epoch 327/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3808 - acc: 0.8314 - val_loss: 0.4126 - val_acc: 0.8067\n",
      "Epoch 328/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.3732 - acc: 0.8400 - val_loss: 0.4119 - val_acc: 0.8000\n",
      "Epoch 329/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3830 - acc: 0.8229 - val_loss: 0.4220 - val_acc: 0.7933\n",
      "Epoch 330/500\n",
      "350/350 [==============================] - 0s 98us/step - loss: 0.3825 - acc: 0.8371 - val_loss: 0.4144 - val_acc: 0.8133\n",
      "Epoch 331/500\n",
      "350/350 [==============================] - 0s 106us/step - loss: 0.3769 - acc: 0.8314 - val_loss: 0.4188 - val_acc: 0.7933\n",
      "Epoch 332/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.3752 - acc: 0.8400 - val_loss: 0.4160 - val_acc: 0.8133\n",
      "Epoch 333/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3722 - acc: 0.8343 - val_loss: 0.4165 - val_acc: 0.7933\n",
      "Epoch 334/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3725 - acc: 0.8286 - val_loss: 0.4138 - val_acc: 0.8000\n",
      "Epoch 335/500\n",
      "350/350 [==============================] - 0s 102us/step - loss: 0.3875 - acc: 0.8400 - val_loss: 0.4115 - val_acc: 0.8133\n",
      "Epoch 336/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.3827 - acc: 0.8486 - val_loss: 0.4125 - val_acc: 0.8133\n",
      "Epoch 337/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3795 - acc: 0.8286 - val_loss: 0.4285 - val_acc: 0.7867\n",
      "Epoch 338/500\n",
      "350/350 [==============================] - 0s 106us/step - loss: 0.3805 - acc: 0.8257 - val_loss: 0.4125 - val_acc: 0.7933\n",
      "Epoch 339/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3785 - acc: 0.8343 - val_loss: 0.4124 - val_acc: 0.8133\n",
      "Epoch 340/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3762 - acc: 0.8343 - val_loss: 0.4127 - val_acc: 0.8133\n",
      "Epoch 341/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3738 - acc: 0.8343 - val_loss: 0.4122 - val_acc: 0.8000\n",
      "Epoch 342/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3733 - acc: 0.8457 - val_loss: 0.4135 - val_acc: 0.8000\n",
      "Epoch 343/500\n",
      "350/350 [==============================] - 0s 98us/step - loss: 0.3714 - acc: 0.8343 - val_loss: 0.4128 - val_acc: 0.8200\n",
      "Epoch 344/500\n",
      "350/350 [==============================] - 0s 108us/step - loss: 0.3779 - acc: 0.8400 - val_loss: 0.4127 - val_acc: 0.8133\n",
      "Epoch 345/500\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.3789 - acc: 0.8343 - val_loss: 0.4135 - val_acc: 0.7933\n",
      "Epoch 346/500\n",
      "350/350 [==============================] - 0s 89us/step - loss: 0.3772 - acc: 0.8371 - val_loss: 0.4138 - val_acc: 0.7933\n",
      "Epoch 347/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3772 - acc: 0.8343 - val_loss: 0.4179 - val_acc: 0.8133\n",
      "Epoch 348/500\n",
      "350/350 [==============================] - 0s 89us/step - loss: 0.3755 - acc: 0.8429 - val_loss: 0.4389 - val_acc: 0.7800\n",
      "Epoch 349/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3766 - acc: 0.8343 - val_loss: 0.4135 - val_acc: 0.8133\n",
      "Epoch 350/500\n",
      "350/350 [==============================] - 0s 104us/step - loss: 0.3713 - acc: 0.8257 - val_loss: 0.4152 - val_acc: 0.7933\n",
      "Epoch 351/500\n",
      "350/350 [==============================] - 0s 104us/step - loss: 0.3770 - acc: 0.8400 - val_loss: 0.4144 - val_acc: 0.8067\n",
      "Epoch 352/500\n",
      "350/350 [==============================] - 0s 115us/step - loss: 0.3680 - acc: 0.8371 - val_loss: 0.4163 - val_acc: 0.8000\n",
      "Epoch 353/500\n",
      "350/350 [==============================] - 0s 98us/step - loss: 0.3704 - acc: 0.8257 - val_loss: 0.4203 - val_acc: 0.8067\n",
      "Epoch 354/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3818 - acc: 0.8314 - val_loss: 0.4485 - val_acc: 0.7933\n",
      "Epoch 355/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3715 - acc: 0.8343 - val_loss: 0.4121 - val_acc: 0.8067\n",
      "Epoch 356/500\n",
      "350/350 [==============================] - 0s 106us/step - loss: 0.3626 - acc: 0.8371 - val_loss: 0.4328 - val_acc: 0.7533\n",
      "Epoch 357/500\n",
      "350/350 [==============================] - 0s 103us/step - loss: 0.3796 - acc: 0.8514 - val_loss: 0.4326 - val_acc: 0.7867\n",
      "Epoch 358/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3809 - acc: 0.8343 - val_loss: 0.4190 - val_acc: 0.8067\n",
      "Epoch 359/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3731 - acc: 0.8457 - val_loss: 0.4218 - val_acc: 0.7933\n",
      "Epoch 360/500\n",
      "350/350 [==============================] - 0s 89us/step - loss: 0.3727 - acc: 0.8457 - val_loss: 0.4137 - val_acc: 0.7800\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 92us/step - loss: 0.3766 - acc: 0.8286 - val_loss: 0.4354 - val_acc: 0.8000\n",
      "Epoch 362/500\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.3825 - acc: 0.8457 - val_loss: 0.4181 - val_acc: 0.8000\n",
      "Epoch 363/500\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.3771 - acc: 0.8429 - val_loss: 0.4174 - val_acc: 0.8133\n",
      "Epoch 364/500\n",
      "350/350 [==============================] - 0s 164us/step - loss: 0.3787 - acc: 0.8400 - val_loss: 0.4143 - val_acc: 0.8000\n",
      "Epoch 365/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3688 - acc: 0.8429 - val_loss: 0.4485 - val_acc: 0.7867\n",
      "Epoch 366/500\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.3767 - acc: 0.8457 - val_loss: 0.4288 - val_acc: 0.7933\n",
      "Epoch 367/500\n",
      "350/350 [==============================] - 0s 106us/step - loss: 0.3769 - acc: 0.8371 - val_loss: 0.4177 - val_acc: 0.8133\n",
      "Epoch 368/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3788 - acc: 0.8343 - val_loss: 0.4453 - val_acc: 0.7867\n",
      "Epoch 369/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3770 - acc: 0.8343 - val_loss: 0.4173 - val_acc: 0.8133\n",
      "Epoch 370/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3691 - acc: 0.8200 - val_loss: 0.4236 - val_acc: 0.8000\n",
      "Epoch 371/500\n",
      "350/350 [==============================] - 0s 89us/step - loss: 0.3721 - acc: 0.8286 - val_loss: 0.4344 - val_acc: 0.7867\n",
      "Epoch 372/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3731 - acc: 0.8457 - val_loss: 0.4458 - val_acc: 0.8000\n",
      "Epoch 373/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3716 - acc: 0.8400 - val_loss: 0.4194 - val_acc: 0.7933\n",
      "Epoch 374/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.3701 - acc: 0.8343 - val_loss: 0.4175 - val_acc: 0.8000\n",
      "Epoch 375/500\n",
      "350/350 [==============================] - 0s 115us/step - loss: 0.3701 - acc: 0.8371 - val_loss: 0.4131 - val_acc: 0.7867\n",
      "Epoch 376/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3903 - acc: 0.8229 - val_loss: 0.4093 - val_acc: 0.8067\n",
      "Epoch 377/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3807 - acc: 0.8143 - val_loss: 0.4120 - val_acc: 0.8000\n",
      "Epoch 378/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3717 - acc: 0.8286 - val_loss: 0.4084 - val_acc: 0.8067\n",
      "Epoch 379/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3714 - acc: 0.8371 - val_loss: 0.4268 - val_acc: 0.7867\n",
      "Epoch 380/500\n",
      "350/350 [==============================] - 0s 102us/step - loss: 0.3733 - acc: 0.8400 - val_loss: 0.4163 - val_acc: 0.7867\n",
      "Epoch 381/500\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.3724 - acc: 0.8257 - val_loss: 0.4234 - val_acc: 0.7800\n",
      "Epoch 382/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3937 - acc: 0.8200 - val_loss: 0.4152 - val_acc: 0.7933\n",
      "Epoch 383/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3744 - acc: 0.8371 - val_loss: 0.4118 - val_acc: 0.8067\n",
      "Epoch 384/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3665 - acc: 0.8429 - val_loss: 0.4136 - val_acc: 0.8000\n",
      "Epoch 385/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3705 - acc: 0.8314 - val_loss: 0.4243 - val_acc: 0.8000\n",
      "Epoch 386/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3747 - acc: 0.8343 - val_loss: 0.4342 - val_acc: 0.7867\n",
      "Epoch 387/500\n",
      "350/350 [==============================] - 0s 104us/step - loss: 0.3677 - acc: 0.8400 - val_loss: 0.4094 - val_acc: 0.8067\n",
      "Epoch 388/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3745 - acc: 0.8457 - val_loss: 0.4244 - val_acc: 0.7867\n",
      "Epoch 389/500\n",
      "350/350 [==============================] - 0s 88us/step - loss: 0.3776 - acc: 0.8286 - val_loss: 0.4404 - val_acc: 0.7867\n",
      "Epoch 390/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3864 - acc: 0.8143 - val_loss: 0.4311 - val_acc: 0.7867\n",
      "Epoch 391/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3692 - acc: 0.8229 - val_loss: 0.4209 - val_acc: 0.8067\n",
      "Epoch 392/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3732 - acc: 0.8314 - val_loss: 0.4251 - val_acc: 0.7933\n",
      "Epoch 393/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3714 - acc: 0.8343 - val_loss: 0.4284 - val_acc: 0.7933\n",
      "Epoch 394/500\n",
      "350/350 [==============================] - 0s 104us/step - loss: 0.3773 - acc: 0.8343 - val_loss: 0.4173 - val_acc: 0.8133\n",
      "Epoch 395/500\n",
      "350/350 [==============================] - 0s 108us/step - loss: 0.3750 - acc: 0.8429 - val_loss: 0.4869 - val_acc: 0.8000\n",
      "Epoch 396/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3816 - acc: 0.8229 - val_loss: 0.4668 - val_acc: 0.7867\n",
      "Epoch 397/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3784 - acc: 0.8486 - val_loss: 0.4238 - val_acc: 0.7933\n",
      "Epoch 398/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.3809 - acc: 0.8286 - val_loss: 0.4239 - val_acc: 0.8000\n",
      "Epoch 399/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3742 - acc: 0.8429 - val_loss: 0.4259 - val_acc: 0.7933\n",
      "Epoch 400/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3765 - acc: 0.8314 - val_loss: 0.4103 - val_acc: 0.8133\n",
      "Epoch 401/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3671 - acc: 0.8457 - val_loss: 0.4167 - val_acc: 0.7867\n",
      "Epoch 402/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3651 - acc: 0.8371 - val_loss: 0.4285 - val_acc: 0.7933\n",
      "Epoch 403/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3706 - acc: 0.8400 - val_loss: 0.4092 - val_acc: 0.7933\n",
      "Epoch 404/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3720 - acc: 0.8257 - val_loss: 0.4223 - val_acc: 0.7933\n",
      "Epoch 405/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.3700 - acc: 0.8200 - val_loss: 0.4096 - val_acc: 0.7933\n",
      "Epoch 406/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3669 - acc: 0.8371 - val_loss: 0.4164 - val_acc: 0.7800\n",
      "Epoch 407/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3775 - acc: 0.8314 - val_loss: 0.4187 - val_acc: 0.7933\n",
      "Epoch 408/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3810 - acc: 0.8400 - val_loss: 0.4108 - val_acc: 0.8000\n",
      "Epoch 409/500\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.3660 - acc: 0.8457 - val_loss: 0.4101 - val_acc: 0.7933\n",
      "Epoch 410/500\n",
      "350/350 [==============================] - 0s 102us/step - loss: 0.3693 - acc: 0.8400 - val_loss: 0.4150 - val_acc: 0.8133\n",
      "Epoch 411/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.3793 - acc: 0.8371 - val_loss: 0.4274 - val_acc: 0.7933\n",
      "Epoch 412/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3814 - acc: 0.8400 - val_loss: 0.4445 - val_acc: 0.7867\n",
      "Epoch 413/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3695 - acc: 0.8286 - val_loss: 0.4423 - val_acc: 0.7867\n",
      "Epoch 414/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3666 - acc: 0.8314 - val_loss: 0.4122 - val_acc: 0.8000\n",
      "Epoch 415/500\n",
      "350/350 [==============================] - 0s 111us/step - loss: 0.3862 - acc: 0.8286 - val_loss: 0.4390 - val_acc: 0.7933\n",
      "Epoch 416/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3765 - acc: 0.8457 - val_loss: 0.4702 - val_acc: 0.8000\n",
      "Epoch 417/500\n",
      "350/350 [==============================] - 0s 101us/step - loss: 0.3678 - acc: 0.8229 - val_loss: 0.4263 - val_acc: 0.7933\n",
      "Epoch 418/500\n",
      "350/350 [==============================] - 0s 100us/step - loss: 0.3759 - acc: 0.8486 - val_loss: 0.4103 - val_acc: 0.8000\n",
      "Epoch 419/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3653 - acc: 0.8371 - val_loss: 0.4257 - val_acc: 0.7867\n",
      "Epoch 420/500\n",
      "350/350 [==============================] - 0s 112us/step - loss: 0.3661 - acc: 0.8371 - val_loss: 0.4089 - val_acc: 0.8067\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 127us/step - loss: 0.3690 - acc: 0.8371 - val_loss: 0.4164 - val_acc: 0.7933\n",
      "Epoch 422/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.3680 - acc: 0.8486 - val_loss: 0.4270 - val_acc: 0.7933\n",
      "Epoch 423/500\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.3717 - acc: 0.8314 - val_loss: 0.4181 - val_acc: 0.7933\n",
      "Epoch 424/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3669 - acc: 0.8314 - val_loss: 0.4128 - val_acc: 0.7933\n",
      "Epoch 425/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3664 - acc: 0.8457 - val_loss: 0.4242 - val_acc: 0.7933\n",
      "Epoch 426/500\n",
      "350/350 [==============================] - 0s 106us/step - loss: 0.3731 - acc: 0.8400 - val_loss: 0.4101 - val_acc: 0.8000\n",
      "Epoch 427/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3688 - acc: 0.8343 - val_loss: 0.4253 - val_acc: 0.7867\n",
      "Epoch 428/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.3719 - acc: 0.8429 - val_loss: 0.4262 - val_acc: 0.7933\n",
      "Epoch 429/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3676 - acc: 0.8429 - val_loss: 0.4155 - val_acc: 0.7933\n",
      "Epoch 430/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.3682 - acc: 0.8457 - val_loss: 0.4132 - val_acc: 0.7933\n",
      "Epoch 431/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3784 - acc: 0.8400 - val_loss: 0.4087 - val_acc: 0.8067\n",
      "Epoch 432/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3698 - acc: 0.8400 - val_loss: 0.4081 - val_acc: 0.8067\n",
      "Epoch 433/500\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.3696 - acc: 0.8314 - val_loss: 0.4084 - val_acc: 0.8067\n",
      "Epoch 434/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3745 - acc: 0.8200 - val_loss: 0.4098 - val_acc: 0.8133\n",
      "Epoch 435/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3732 - acc: 0.8429 - val_loss: 0.4111 - val_acc: 0.7933\n",
      "Epoch 436/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.3630 - acc: 0.8486 - val_loss: 0.4111 - val_acc: 0.8133\n",
      "Epoch 437/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3701 - acc: 0.8229 - val_loss: 0.4144 - val_acc: 0.8067\n",
      "Epoch 438/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3723 - acc: 0.8429 - val_loss: 0.4185 - val_acc: 0.8000\n",
      "Epoch 439/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3661 - acc: 0.8457 - val_loss: 0.4113 - val_acc: 0.7933\n",
      "Epoch 440/500\n",
      "350/350 [==============================] - 0s 159us/step - loss: 0.3658 - acc: 0.8486 - val_loss: 0.4105 - val_acc: 0.7933\n",
      "Epoch 441/500\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.3790 - acc: 0.8171 - val_loss: 0.4155 - val_acc: 0.8000\n",
      "Epoch 442/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3663 - acc: 0.8457 - val_loss: 0.4123 - val_acc: 0.8067\n",
      "Epoch 443/500\n",
      "350/350 [==============================] - 0s 109us/step - loss: 0.3753 - acc: 0.8400 - val_loss: 0.4101 - val_acc: 0.8000\n",
      "Epoch 444/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3689 - acc: 0.8286 - val_loss: 0.4293 - val_acc: 0.7933\n",
      "Epoch 445/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3632 - acc: 0.8571 - val_loss: 0.4125 - val_acc: 0.7933\n",
      "Epoch 446/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3758 - acc: 0.8314 - val_loss: 0.4303 - val_acc: 0.8000\n",
      "Epoch 447/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3679 - acc: 0.8486 - val_loss: 0.4243 - val_acc: 0.7867\n",
      "Epoch 448/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3693 - acc: 0.8571 - val_loss: 0.4329 - val_acc: 0.7933\n",
      "Epoch 449/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3679 - acc: 0.8400 - val_loss: 0.4121 - val_acc: 0.8133\n",
      "Epoch 450/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3675 - acc: 0.8514 - val_loss: 0.4083 - val_acc: 0.8133\n",
      "Epoch 451/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3691 - acc: 0.8257 - val_loss: 0.4241 - val_acc: 0.7933\n",
      "Epoch 452/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3744 - acc: 0.8286 - val_loss: 0.4342 - val_acc: 0.8000\n",
      "Epoch 453/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3751 - acc: 0.8457 - val_loss: 0.4362 - val_acc: 0.7933\n",
      "Epoch 454/500\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.3752 - acc: 0.8429 - val_loss: 0.4570 - val_acc: 0.7867\n",
      "Epoch 455/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3801 - acc: 0.8400 - val_loss: 0.4072 - val_acc: 0.7933\n",
      "Epoch 456/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3701 - acc: 0.8286 - val_loss: 0.4114 - val_acc: 0.8067\n",
      "Epoch 457/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3663 - acc: 0.8314 - val_loss: 0.4190 - val_acc: 0.8000\n",
      "Epoch 458/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3659 - acc: 0.8257 - val_loss: 0.4160 - val_acc: 0.7933\n",
      "Epoch 459/500\n",
      "350/350 [==============================] - 0s 106us/step - loss: 0.3749 - acc: 0.8257 - val_loss: 0.4272 - val_acc: 0.7933\n",
      "Epoch 460/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3848 - acc: 0.8343 - val_loss: 0.4361 - val_acc: 0.7933\n",
      "Epoch 461/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3605 - acc: 0.8514 - val_loss: 0.4083 - val_acc: 0.7933\n",
      "Epoch 462/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3665 - acc: 0.8343 - val_loss: 0.4099 - val_acc: 0.8067\n",
      "Epoch 463/500\n",
      "350/350 [==============================] - 0s 88us/step - loss: 0.3680 - acc: 0.8486 - val_loss: 0.4154 - val_acc: 0.8000\n",
      "Epoch 464/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3621 - acc: 0.8429 - val_loss: 0.4213 - val_acc: 0.7867\n",
      "Epoch 465/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3697 - acc: 0.8457 - val_loss: 0.4150 - val_acc: 0.7933\n",
      "Epoch 466/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3689 - acc: 0.8371 - val_loss: 0.4144 - val_acc: 0.8067\n",
      "Epoch 467/500\n",
      "350/350 [==============================] - 0s 88us/step - loss: 0.3667 - acc: 0.8486 - val_loss: 0.4101 - val_acc: 0.8000\n",
      "Epoch 468/500\n",
      "350/350 [==============================] - 0s 89us/step - loss: 0.3764 - acc: 0.8314 - val_loss: 0.4094 - val_acc: 0.7867\n",
      "Epoch 469/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3730 - acc: 0.8543 - val_loss: 0.4112 - val_acc: 0.7933\n",
      "Epoch 470/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3677 - acc: 0.8371 - val_loss: 0.4110 - val_acc: 0.8067\n",
      "Epoch 471/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3648 - acc: 0.8457 - val_loss: 0.4161 - val_acc: 0.8200\n",
      "Epoch 472/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3712 - acc: 0.8429 - val_loss: 0.4306 - val_acc: 0.7867\n",
      "Epoch 473/500\n",
      "350/350 [==============================] - 0s 102us/step - loss: 0.3663 - acc: 0.8200 - val_loss: 0.4283 - val_acc: 0.7867\n",
      "Epoch 474/500\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.3694 - acc: 0.8400 - val_loss: 0.4095 - val_acc: 0.8000\n",
      "Epoch 475/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3673 - acc: 0.8371 - val_loss: 0.4097 - val_acc: 0.7867\n",
      "Epoch 476/500\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.3637 - acc: 0.8429 - val_loss: 0.4196 - val_acc: 0.7867\n",
      "Epoch 477/500\n",
      "350/350 [==============================] - 0s 98us/step - loss: 0.3684 - acc: 0.8371 - val_loss: 0.4154 - val_acc: 0.8133\n",
      "Epoch 478/500\n",
      "350/350 [==============================] - 0s 94us/step - loss: 0.3625 - acc: 0.8543 - val_loss: 0.4093 - val_acc: 0.8067\n",
      "Epoch 479/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3679 - acc: 0.8400 - val_loss: 0.4071 - val_acc: 0.8067\n",
      "Epoch 480/500\n",
      "350/350 [==============================] - 0s 96us/step - loss: 0.3642 - acc: 0.8286 - val_loss: 0.4143 - val_acc: 0.8133\n",
      "Epoch 481/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 97us/step - loss: 0.3751 - acc: 0.8400 - val_loss: 0.4073 - val_acc: 0.8133\n",
      "Epoch 482/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3692 - acc: 0.8286 - val_loss: 0.4093 - val_acc: 0.8000\n",
      "Epoch 483/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3586 - acc: 0.8343 - val_loss: 0.4185 - val_acc: 0.7733\n",
      "Epoch 484/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.4066 - acc: 0.8114 - val_loss: 0.4261 - val_acc: 0.7600\n",
      "Epoch 485/500\n",
      "350/350 [==============================] - 0s 97us/step - loss: 0.3830 - acc: 0.8200 - val_loss: 0.4314 - val_acc: 0.7733\n",
      "Epoch 486/500\n",
      "350/350 [==============================] - 0s 95us/step - loss: 0.3657 - acc: 0.8543 - val_loss: 0.4090 - val_acc: 0.7933\n",
      "Epoch 487/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3806 - acc: 0.8286 - val_loss: 0.4082 - val_acc: 0.7933\n",
      "Epoch 488/500\n",
      "350/350 [==============================] - 0s 102us/step - loss: 0.3719 - acc: 0.8257 - val_loss: 0.4077 - val_acc: 0.8067\n",
      "Epoch 489/500\n",
      "350/350 [==============================] - 0s 90us/step - loss: 0.3647 - acc: 0.8486 - val_loss: 0.4076 - val_acc: 0.7867\n",
      "Epoch 490/500\n",
      "350/350 [==============================] - 0s 93us/step - loss: 0.3753 - acc: 0.8314 - val_loss: 0.4430 - val_acc: 0.7800\n",
      "Epoch 491/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3734 - acc: 0.8314 - val_loss: 0.4082 - val_acc: 0.8133\n",
      "Epoch 492/500\n",
      "350/350 [==============================] - 0s 86us/step - loss: 0.3779 - acc: 0.8314 - val_loss: 0.4105 - val_acc: 0.7933\n",
      "Epoch 493/500\n",
      "350/350 [==============================] - 0s 92us/step - loss: 0.3654 - acc: 0.8486 - val_loss: 0.4085 - val_acc: 0.7933\n",
      "Epoch 494/500\n",
      "350/350 [==============================] - 0s 89us/step - loss: 0.3651 - acc: 0.8400 - val_loss: 0.4099 - val_acc: 0.8000\n",
      "Epoch 495/500\n",
      "350/350 [==============================] - 0s 87us/step - loss: 0.3637 - acc: 0.8486 - val_loss: 0.4611 - val_acc: 0.8000\n",
      "Epoch 496/500\n",
      "350/350 [==============================] - 0s 86us/step - loss: 0.3677 - acc: 0.8600 - val_loss: 0.4102 - val_acc: 0.8000\n",
      "Epoch 497/500\n",
      "350/350 [==============================] - 0s 99us/step - loss: 0.3860 - acc: 0.8114 - val_loss: 0.4061 - val_acc: 0.7933\n",
      "Epoch 498/500\n",
      "350/350 [==============================] - 0s 91us/step - loss: 0.3707 - acc: 0.8343 - val_loss: 0.4082 - val_acc: 0.8000\n",
      "Epoch 499/500\n",
      "350/350 [==============================] - 0s 89us/step - loss: 0.3644 - acc: 0.8600 - val_loss: 0.4206 - val_acc: 0.8000\n",
      "Epoch 500/500\n",
      "350/350 [==============================] - 0s 105us/step - loss: 0.3804 - acc: 0.8457 - val_loss: 0.4111 - val_acc: 0.8000\n"
     ]
    }
   ],
   "source": [
    "var = classifier.fit(X_train,y_train, batch_size=10, epochs=500, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Treino')\n",
    "plt.grid(True)\n",
    "plt.plot(var.history['acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Teste')\n",
    "plt.grid(True)\n",
    "plt.plot(var.history['val_acc'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
