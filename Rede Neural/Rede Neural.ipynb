{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('/home/matheusrmeloo/Documentos/ML/graduate-admissions/Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1                 1  \n",
       "1         1                 1  \n",
       "2         1                 1  \n",
       "3         1                 1  \n",
       "4         0                 0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['Chance of Admit '] = (data_frame['Chance of Admit '] >= .7).astype(int)\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_frame[['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research']].values.tolist()\n",
    "\n",
    "data = keras.utils.to_categorical(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data_frame[['Chance of Admit ']].values.tolist()\n",
    "\n",
    "data2 = keras.utils.to_categorical(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_frame.iloc[:,0:8]\n",
    "y = data_frame.iloc[:,8]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal', input_dim=X_train.shape[-1]))\n",
    "\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal'))\n",
    "\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 350 samples, validate on 150 samples\n",
      "Epoch 1/500\n",
      "350/350 [==============================] - 1s 2ms/step - loss: 0.7018 - acc: 0.4829 - val_loss: 0.6843 - val_acc: 0.5867\n",
      "Epoch 2/500\n",
      "350/350 [==============================] - 0s 157us/step - loss: 0.6775 - acc: 0.6057 - val_loss: 0.6752 - val_acc: 0.5867\n",
      "Epoch 3/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.6698 - acc: 0.6057 - val_loss: 0.6743 - val_acc: 0.5867\n",
      "Epoch 4/500\n",
      "350/350 [==============================] - 0s 152us/step - loss: 0.6700 - acc: 0.6057 - val_loss: 0.6739 - val_acc: 0.5867\n",
      "Epoch 5/500\n",
      "350/350 [==============================] - 0s 150us/step - loss: 0.6679 - acc: 0.6057 - val_loss: 0.6736 - val_acc: 0.5867\n",
      "Epoch 6/500\n",
      "350/350 [==============================] - 0s 151us/step - loss: 0.6675 - acc: 0.6057 - val_loss: 0.6737 - val_acc: 0.5867\n",
      "Epoch 7/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.6661 - acc: 0.6057 - val_loss: 0.6727 - val_acc: 0.5867\n",
      "Epoch 8/500\n",
      "350/350 [==============================] - 0s 151us/step - loss: 0.6658 - acc: 0.6057 - val_loss: 0.6725 - val_acc: 0.5867\n",
      "Epoch 9/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.6656 - acc: 0.6057 - val_loss: 0.6722 - val_acc: 0.5867\n",
      "Epoch 10/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.6646 - acc: 0.6057 - val_loss: 0.6721 - val_acc: 0.5867\n",
      "Epoch 11/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.6614 - acc: 0.6057 - val_loss: 0.6691 - val_acc: 0.5867\n",
      "Epoch 12/500\n",
      "350/350 [==============================] - 0s 158us/step - loss: 0.6613 - acc: 0.6000 - val_loss: 0.6687 - val_acc: 0.5867\n",
      "Epoch 13/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.6607 - acc: 0.6057 - val_loss: 0.6678 - val_acc: 0.5867\n",
      "Epoch 14/500\n",
      "350/350 [==============================] - 0s 177us/step - loss: 0.6584 - acc: 0.6057 - val_loss: 0.6657 - val_acc: 0.5733\n",
      "Epoch 15/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.6544 - acc: 0.6086 - val_loss: 0.6639 - val_acc: 0.5867\n",
      "Epoch 16/500\n",
      "350/350 [==============================] - 0s 159us/step - loss: 0.6533 - acc: 0.6057 - val_loss: 0.6619 - val_acc: 0.6067\n",
      "Epoch 17/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.6493 - acc: 0.6086 - val_loss: 0.6598 - val_acc: 0.6067\n",
      "Epoch 18/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.6469 - acc: 0.6200 - val_loss: 0.6574 - val_acc: 0.6067\n",
      "Epoch 19/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.6402 - acc: 0.6029 - val_loss: 0.6543 - val_acc: 0.6000\n",
      "Epoch 20/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.6365 - acc: 0.6257 - val_loss: 0.6504 - val_acc: 0.6067\n",
      "Epoch 21/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.6293 - acc: 0.6343 - val_loss: 0.6494 - val_acc: 0.6067\n",
      "Epoch 22/500\n",
      "350/350 [==============================] - 0s 176us/step - loss: 0.6292 - acc: 0.6257 - val_loss: 0.6435 - val_acc: 0.5933\n",
      "Epoch 23/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.6214 - acc: 0.6371 - val_loss: 0.6424 - val_acc: 0.5933\n",
      "Epoch 24/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.6175 - acc: 0.6486 - val_loss: 0.6411 - val_acc: 0.6133\n",
      "Epoch 25/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.6127 - acc: 0.6943 - val_loss: 0.6344 - val_acc: 0.6267\n",
      "Epoch 26/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.6176 - acc: 0.6229 - val_loss: 0.6381 - val_acc: 0.6067\n",
      "Epoch 27/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.6091 - acc: 0.6743 - val_loss: 0.6395 - val_acc: 0.6333\n",
      "Epoch 28/500\n",
      "350/350 [==============================] - 0s 150us/step - loss: 0.5989 - acc: 0.6629 - val_loss: 0.6229 - val_acc: 0.6400\n",
      "Epoch 29/500\n",
      "350/350 [==============================] - 0s 159us/step - loss: 0.5904 - acc: 0.6971 - val_loss: 0.6185 - val_acc: 0.6467\n",
      "Epoch 30/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.5857 - acc: 0.6886 - val_loss: 0.6234 - val_acc: 0.6267\n",
      "Epoch 31/500\n",
      "350/350 [==============================] - 0s 160us/step - loss: 0.5895 - acc: 0.6771 - val_loss: 0.6210 - val_acc: 0.6533\n",
      "Epoch 32/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.5949 - acc: 0.6714 - val_loss: 0.6132 - val_acc: 0.6400\n",
      "Epoch 33/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.5788 - acc: 0.7029 - val_loss: 0.6397 - val_acc: 0.6400\n",
      "Epoch 34/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.5731 - acc: 0.7000 - val_loss: 0.5999 - val_acc: 0.6800\n",
      "Epoch 35/500\n",
      "350/350 [==============================] - 0s 152us/step - loss: 0.5671 - acc: 0.6971 - val_loss: 0.6012 - val_acc: 0.6667\n",
      "Epoch 36/500\n",
      "350/350 [==============================] - 0s 194us/step - loss: 0.5600 - acc: 0.7029 - val_loss: 0.5902 - val_acc: 0.6600\n",
      "Epoch 37/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.5481 - acc: 0.7171 - val_loss: 0.6464 - val_acc: 0.6200\n",
      "Epoch 38/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.5670 - acc: 0.7086 - val_loss: 0.5889 - val_acc: 0.6600\n",
      "Epoch 39/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.5429 - acc: 0.7257 - val_loss: 0.5692 - val_acc: 0.7267\n",
      "Epoch 40/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.5398 - acc: 0.7457 - val_loss: 0.5665 - val_acc: 0.6867\n",
      "Epoch 41/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.5297 - acc: 0.7543 - val_loss: 0.5600 - val_acc: 0.6867\n",
      "Epoch 42/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.5226 - acc: 0.7400 - val_loss: 0.5636 - val_acc: 0.7133\n",
      "Epoch 43/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.5295 - acc: 0.7400 - val_loss: 0.5469 - val_acc: 0.7133\n",
      "Epoch 44/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.5135 - acc: 0.7571 - val_loss: 0.5434 - val_acc: 0.7200\n",
      "Epoch 45/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.5201 - acc: 0.7429 - val_loss: 0.5399 - val_acc: 0.7067\n",
      "Epoch 46/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.5108 - acc: 0.7429 - val_loss: 0.5323 - val_acc: 0.7400\n",
      "Epoch 47/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.5024 - acc: 0.7743 - val_loss: 0.5309 - val_acc: 0.7467\n",
      "Epoch 48/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.4931 - acc: 0.7400 - val_loss: 0.5269 - val_acc: 0.7200\n",
      "Epoch 49/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.4849 - acc: 0.7857 - val_loss: 0.5259 - val_acc: 0.7200\n",
      "Epoch 50/500\n",
      "350/350 [==============================] - 0s 151us/step - loss: 0.5233 - acc: 0.7486 - val_loss: 0.6505 - val_acc: 0.6200\n",
      "Epoch 51/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.5266 - acc: 0.7086 - val_loss: 0.5142 - val_acc: 0.7467\n",
      "Epoch 52/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.4988 - acc: 0.7543 - val_loss: 0.5103 - val_acc: 0.7333\n",
      "Epoch 53/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.4826 - acc: 0.7514 - val_loss: 0.5055 - val_acc: 0.7467\n",
      "Epoch 54/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.4750 - acc: 0.7743 - val_loss: 0.4987 - val_acc: 0.7400\n",
      "Epoch 55/500\n",
      "350/350 [==============================] - 0s 152us/step - loss: 0.4696 - acc: 0.7686 - val_loss: 0.4963 - val_acc: 0.7467\n",
      "Epoch 56/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.4644 - acc: 0.7743 - val_loss: 0.4981 - val_acc: 0.7400\n",
      "Epoch 57/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.4669 - acc: 0.7829 - val_loss: 0.5058 - val_acc: 0.7200\n",
      "Epoch 58/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.4549 - acc: 0.7857 - val_loss: 0.4965 - val_acc: 0.7467\n",
      "Epoch 59/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.4657 - acc: 0.7714 - val_loss: 0.4954 - val_acc: 0.7600\n",
      "Epoch 60/500\n",
      "350/350 [==============================] - 0s 157us/step - loss: 0.4658 - acc: 0.7686 - val_loss: 0.4792 - val_acc: 0.7467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.4466 - acc: 0.7886 - val_loss: 0.4789 - val_acc: 0.7600\n",
      "Epoch 62/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.4407 - acc: 0.7971 - val_loss: 0.4714 - val_acc: 0.7533\n",
      "Epoch 63/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.4435 - acc: 0.7771 - val_loss: 0.4761 - val_acc: 0.7667\n",
      "Epoch 64/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.4377 - acc: 0.8029 - val_loss: 0.4752 - val_acc: 0.7600\n",
      "Epoch 65/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.4299 - acc: 0.8000 - val_loss: 0.4646 - val_acc: 0.7667\n",
      "Epoch 66/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.4252 - acc: 0.8029 - val_loss: 0.4740 - val_acc: 0.7667\n",
      "Epoch 67/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.4415 - acc: 0.7829 - val_loss: 0.4924 - val_acc: 0.7333\n",
      "Epoch 68/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.4315 - acc: 0.8086 - val_loss: 0.4605 - val_acc: 0.7533\n",
      "Epoch 69/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.4323 - acc: 0.7914 - val_loss: 0.4577 - val_acc: 0.7667\n",
      "Epoch 70/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.4432 - acc: 0.7886 - val_loss: 0.4493 - val_acc: 0.7533\n",
      "Epoch 71/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.4163 - acc: 0.8114 - val_loss: 0.4604 - val_acc: 0.7733\n",
      "Epoch 72/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.4363 - acc: 0.7886 - val_loss: 0.4476 - val_acc: 0.7600\n",
      "Epoch 73/500\n",
      "350/350 [==============================] - 0s 152us/step - loss: 0.4200 - acc: 0.7943 - val_loss: 0.4470 - val_acc: 0.7867\n",
      "Epoch 74/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.4165 - acc: 0.7914 - val_loss: 0.4994 - val_acc: 0.7467\n",
      "Epoch 75/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.4298 - acc: 0.7886 - val_loss: 0.4548 - val_acc: 0.7600\n",
      "Epoch 76/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.4130 - acc: 0.8200 - val_loss: 0.4506 - val_acc: 0.7867\n",
      "Epoch 77/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.4154 - acc: 0.8029 - val_loss: 0.4510 - val_acc: 0.7733\n",
      "Epoch 78/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.4135 - acc: 0.8114 - val_loss: 0.4428 - val_acc: 0.7800\n",
      "Epoch 79/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.4038 - acc: 0.8200 - val_loss: 0.4434 - val_acc: 0.7800\n",
      "Epoch 80/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.4059 - acc: 0.8143 - val_loss: 0.4352 - val_acc: 0.7667\n",
      "Epoch 81/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.4128 - acc: 0.8029 - val_loss: 0.4375 - val_acc: 0.7800\n",
      "Epoch 82/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.4079 - acc: 0.8086 - val_loss: 0.4391 - val_acc: 0.7933\n",
      "Epoch 83/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.3976 - acc: 0.8257 - val_loss: 0.4349 - val_acc: 0.7733\n",
      "Epoch 84/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.4001 - acc: 0.8114 - val_loss: 0.4361 - val_acc: 0.7733\n",
      "Epoch 85/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.4057 - acc: 0.8200 - val_loss: 0.4816 - val_acc: 0.7800\n",
      "Epoch 86/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.4108 - acc: 0.8200 - val_loss: 0.4358 - val_acc: 0.8000\n",
      "Epoch 87/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.3963 - acc: 0.8314 - val_loss: 0.4577 - val_acc: 0.7867\n",
      "Epoch 88/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.3945 - acc: 0.8086 - val_loss: 0.4326 - val_acc: 0.7933\n",
      "Epoch 89/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.3952 - acc: 0.8314 - val_loss: 0.4310 - val_acc: 0.7933\n",
      "Epoch 90/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3962 - acc: 0.8057 - val_loss: 0.4370 - val_acc: 0.7867\n",
      "Epoch 91/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.4105 - acc: 0.8114 - val_loss: 0.4427 - val_acc: 0.7867\n",
      "Epoch 92/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3940 - acc: 0.8400 - val_loss: 0.4956 - val_acc: 0.7800\n",
      "Epoch 93/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3960 - acc: 0.8229 - val_loss: 0.4386 - val_acc: 0.7933\n",
      "Epoch 94/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.4021 - acc: 0.8200 - val_loss: 0.4361 - val_acc: 0.7800\n",
      "Epoch 95/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3924 - acc: 0.8229 - val_loss: 0.4304 - val_acc: 0.8067\n",
      "Epoch 96/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3898 - acc: 0.8314 - val_loss: 0.4267 - val_acc: 0.7800\n",
      "Epoch 97/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.3904 - acc: 0.8229 - val_loss: 0.4474 - val_acc: 0.7867\n",
      "Epoch 98/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3930 - acc: 0.8314 - val_loss: 0.4261 - val_acc: 0.7867\n",
      "Epoch 99/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3887 - acc: 0.8200 - val_loss: 0.4265 - val_acc: 0.7800\n",
      "Epoch 100/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3946 - acc: 0.8200 - val_loss: 0.4265 - val_acc: 0.7867\n",
      "Epoch 101/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.4012 - acc: 0.8257 - val_loss: 0.4264 - val_acc: 0.7867\n",
      "Epoch 102/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.3953 - acc: 0.8486 - val_loss: 0.4392 - val_acc: 0.7933\n",
      "Epoch 103/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.4001 - acc: 0.8229 - val_loss: 0.4262 - val_acc: 0.7800\n",
      "Epoch 104/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.3964 - acc: 0.8171 - val_loss: 0.4249 - val_acc: 0.7867\n",
      "Epoch 105/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3841 - acc: 0.8314 - val_loss: 0.4295 - val_acc: 0.7867\n",
      "Epoch 106/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.3847 - acc: 0.8200 - val_loss: 0.4259 - val_acc: 0.7800\n",
      "Epoch 107/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.3818 - acc: 0.8286 - val_loss: 0.4253 - val_acc: 0.7800\n",
      "Epoch 108/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3837 - acc: 0.8314 - val_loss: 0.4261 - val_acc: 0.7867\n",
      "Epoch 109/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3836 - acc: 0.8314 - val_loss: 0.4268 - val_acc: 0.7800\n",
      "Epoch 110/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3855 - acc: 0.8200 - val_loss: 0.4443 - val_acc: 0.7800\n",
      "Epoch 111/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3866 - acc: 0.8257 - val_loss: 0.4499 - val_acc: 0.7867\n",
      "Epoch 112/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3875 - acc: 0.8257 - val_loss: 0.4315 - val_acc: 0.7933\n",
      "Epoch 113/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3872 - acc: 0.8314 - val_loss: 0.4268 - val_acc: 0.7867\n",
      "Epoch 114/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3913 - acc: 0.8057 - val_loss: 0.4250 - val_acc: 0.7800\n",
      "Epoch 115/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.3827 - acc: 0.8229 - val_loss: 0.4595 - val_acc: 0.7867\n",
      "Epoch 116/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3794 - acc: 0.8171 - val_loss: 0.4367 - val_acc: 0.7800\n",
      "Epoch 117/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3936 - acc: 0.8257 - val_loss: 0.4685 - val_acc: 0.7800\n",
      "Epoch 118/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3918 - acc: 0.8371 - val_loss: 0.4548 - val_acc: 0.8000\n",
      "Epoch 119/500\n",
      "350/350 [==============================] - 0s 157us/step - loss: 0.3922 - acc: 0.8257 - val_loss: 0.4277 - val_acc: 0.7933\n",
      "Epoch 120/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3924 - acc: 0.8229 - val_loss: 0.4319 - val_acc: 0.7867\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 132us/step - loss: 0.3968 - acc: 0.8171 - val_loss: 0.4257 - val_acc: 0.7933\n",
      "Epoch 122/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3866 - acc: 0.8371 - val_loss: 0.4303 - val_acc: 0.7867\n",
      "Epoch 123/500\n",
      "350/350 [==============================] - 0s 148us/step - loss: 0.4046 - acc: 0.8114 - val_loss: 0.4582 - val_acc: 0.7933\n",
      "Epoch 124/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3901 - acc: 0.8143 - val_loss: 0.4490 - val_acc: 0.7867\n",
      "Epoch 125/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3878 - acc: 0.8257 - val_loss: 0.4420 - val_acc: 0.7800\n",
      "Epoch 126/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3907 - acc: 0.8057 - val_loss: 0.4255 - val_acc: 0.8000\n",
      "Epoch 127/500\n",
      "350/350 [==============================] - 0s 206us/step - loss: 0.3868 - acc: 0.8171 - val_loss: 0.4392 - val_acc: 0.7800\n",
      "Epoch 128/500\n",
      "350/350 [==============================] - 0s 212us/step - loss: 0.4023 - acc: 0.8314 - val_loss: 0.4271 - val_acc: 0.7867\n",
      "Epoch 129/500\n",
      "350/350 [==============================] - 0s 204us/step - loss: 0.3846 - acc: 0.8286 - val_loss: 0.4259 - val_acc: 0.7933\n",
      "Epoch 130/500\n",
      "350/350 [==============================] - 0s 157us/step - loss: 0.3821 - acc: 0.8343 - val_loss: 0.4374 - val_acc: 0.7800\n",
      "Epoch 131/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3851 - acc: 0.8371 - val_loss: 0.4282 - val_acc: 0.8000\n",
      "Epoch 132/500\n",
      "350/350 [==============================] - 0s 171us/step - loss: 0.3793 - acc: 0.8371 - val_loss: 0.4293 - val_acc: 0.7933\n",
      "Epoch 133/500\n",
      "350/350 [==============================] - 0s 206us/step - loss: 0.3822 - acc: 0.8257 - val_loss: 0.4305 - val_acc: 0.7933\n",
      "Epoch 134/500\n",
      "350/350 [==============================] - 0s 210us/step - loss: 0.3778 - acc: 0.8314 - val_loss: 0.4259 - val_acc: 0.7867\n",
      "Epoch 135/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.3976 - acc: 0.8371 - val_loss: 0.4252 - val_acc: 0.7933\n",
      "Epoch 136/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.3798 - acc: 0.8314 - val_loss: 0.4257 - val_acc: 0.7933\n",
      "Epoch 137/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.3888 - acc: 0.8571 - val_loss: 0.4256 - val_acc: 0.7933\n",
      "Epoch 138/500\n",
      "350/350 [==============================] - 0s 232us/step - loss: 0.3887 - acc: 0.8171 - val_loss: 0.4300 - val_acc: 0.7933\n",
      "Epoch 139/500\n",
      "350/350 [==============================] - 0s 227us/step - loss: 0.3736 - acc: 0.8600 - val_loss: 0.4769 - val_acc: 0.7333\n",
      "Epoch 140/500\n",
      "350/350 [==============================] - 0s 192us/step - loss: 0.4031 - acc: 0.8257 - val_loss: 0.4353 - val_acc: 0.7933\n",
      "Epoch 141/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3847 - acc: 0.8371 - val_loss: 0.4426 - val_acc: 0.7867\n",
      "Epoch 142/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.3856 - acc: 0.8343 - val_loss: 0.4712 - val_acc: 0.7933\n",
      "Epoch 143/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3849 - acc: 0.8286 - val_loss: 0.4271 - val_acc: 0.7867\n",
      "Epoch 144/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3960 - acc: 0.8200 - val_loss: 0.4342 - val_acc: 0.7933\n",
      "Epoch 145/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3847 - acc: 0.8314 - val_loss: 0.4239 - val_acc: 0.7933\n",
      "Epoch 146/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3814 - acc: 0.8314 - val_loss: 0.4232 - val_acc: 0.7933\n",
      "Epoch 147/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3820 - acc: 0.8286 - val_loss: 0.4375 - val_acc: 0.7867\n",
      "Epoch 148/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3903 - acc: 0.8086 - val_loss: 0.4256 - val_acc: 0.7867\n",
      "Epoch 149/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3799 - acc: 0.8286 - val_loss: 0.4489 - val_acc: 0.7867\n",
      "Epoch 150/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.3858 - acc: 0.8257 - val_loss: 0.4632 - val_acc: 0.7933\n",
      "Epoch 151/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.3897 - acc: 0.8400 - val_loss: 0.4282 - val_acc: 0.7867\n",
      "Epoch 152/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3839 - acc: 0.8314 - val_loss: 0.4663 - val_acc: 0.7933\n",
      "Epoch 153/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.4124 - acc: 0.8114 - val_loss: 0.4547 - val_acc: 0.7867\n",
      "Epoch 154/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.3915 - acc: 0.8286 - val_loss: 0.4256 - val_acc: 0.8000\n",
      "Epoch 155/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.3855 - acc: 0.8257 - val_loss: 0.4250 - val_acc: 0.7867\n",
      "Epoch 156/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3894 - acc: 0.8114 - val_loss: 0.4322 - val_acc: 0.7933\n",
      "Epoch 157/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.4002 - acc: 0.8200 - val_loss: 0.4631 - val_acc: 0.7933\n",
      "Epoch 158/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.3904 - acc: 0.8286 - val_loss: 0.4602 - val_acc: 0.7867\n",
      "Epoch 159/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3835 - acc: 0.8229 - val_loss: 0.4259 - val_acc: 0.8000\n",
      "Epoch 160/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.3969 - acc: 0.8171 - val_loss: 0.4418 - val_acc: 0.7800\n",
      "Epoch 161/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3828 - acc: 0.8343 - val_loss: 0.4236 - val_acc: 0.7867\n",
      "Epoch 162/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3882 - acc: 0.8457 - val_loss: 0.4336 - val_acc: 0.7933\n",
      "Epoch 163/500\n",
      "350/350 [==============================] - 0s 156us/step - loss: 0.3991 - acc: 0.8114 - val_loss: 0.4258 - val_acc: 0.8000\n",
      "Epoch 164/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.3812 - acc: 0.8343 - val_loss: 0.4312 - val_acc: 0.7667\n",
      "Epoch 165/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.4109 - acc: 0.8000 - val_loss: 0.5155 - val_acc: 0.7867\n",
      "Epoch 166/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3883 - acc: 0.8143 - val_loss: 0.4257 - val_acc: 0.7933\n",
      "Epoch 167/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.3908 - acc: 0.8200 - val_loss: 0.4240 - val_acc: 0.7933\n",
      "Epoch 168/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3896 - acc: 0.8171 - val_loss: 0.4899 - val_acc: 0.7933\n",
      "Epoch 169/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.3893 - acc: 0.8400 - val_loss: 0.4247 - val_acc: 0.7933\n",
      "Epoch 170/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.3992 - acc: 0.8086 - val_loss: 0.4245 - val_acc: 0.7933\n",
      "Epoch 171/500\n",
      "350/350 [==============================] - 0s 164us/step - loss: 0.3888 - acc: 0.8143 - val_loss: 0.4605 - val_acc: 0.7867\n",
      "Epoch 172/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.3997 - acc: 0.8400 - val_loss: 0.4672 - val_acc: 0.7867\n",
      "Epoch 173/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.3829 - acc: 0.8457 - val_loss: 0.4298 - val_acc: 0.7933\n",
      "Epoch 174/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3810 - acc: 0.8257 - val_loss: 0.4264 - val_acc: 0.7933\n",
      "Epoch 175/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3775 - acc: 0.8343 - val_loss: 0.4493 - val_acc: 0.7867\n",
      "Epoch 176/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.3895 - acc: 0.8400 - val_loss: 0.4491 - val_acc: 0.7867\n",
      "Epoch 177/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3844 - acc: 0.8286 - val_loss: 0.4297 - val_acc: 0.7933\n",
      "Epoch 178/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3849 - acc: 0.8200 - val_loss: 0.4248 - val_acc: 0.7933\n",
      "Epoch 179/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3834 - acc: 0.8314 - val_loss: 0.4287 - val_acc: 0.7867\n",
      "Epoch 180/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.4022 - acc: 0.8200 - val_loss: 0.4427 - val_acc: 0.7733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3808 - acc: 0.8257 - val_loss: 0.4326 - val_acc: 0.7867\n",
      "Epoch 182/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3855 - acc: 0.8457 - val_loss: 0.4519 - val_acc: 0.7800\n",
      "Epoch 183/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.4117 - acc: 0.8114 - val_loss: 0.4229 - val_acc: 0.7933\n",
      "Epoch 184/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.3835 - acc: 0.8229 - val_loss: 0.4275 - val_acc: 0.8067\n",
      "Epoch 185/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3778 - acc: 0.8286 - val_loss: 0.4264 - val_acc: 0.7867\n",
      "Epoch 186/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.3817 - acc: 0.8286 - val_loss: 0.4662 - val_acc: 0.7800\n",
      "Epoch 187/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3827 - acc: 0.8400 - val_loss: 0.4377 - val_acc: 0.7800\n",
      "Epoch 188/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3782 - acc: 0.8457 - val_loss: 0.4297 - val_acc: 0.7933\n",
      "Epoch 189/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3876 - acc: 0.8429 - val_loss: 0.4303 - val_acc: 0.8000\n",
      "Epoch 190/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3849 - acc: 0.8286 - val_loss: 0.4339 - val_acc: 0.7933\n",
      "Epoch 191/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3830 - acc: 0.8171 - val_loss: 0.4293 - val_acc: 0.7933\n",
      "Epoch 192/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3908 - acc: 0.8314 - val_loss: 0.4671 - val_acc: 0.7933\n",
      "Epoch 193/500\n",
      "350/350 [==============================] - 0s 123us/step - loss: 0.3893 - acc: 0.8286 - val_loss: 0.4255 - val_acc: 0.7867\n",
      "Epoch 194/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3779 - acc: 0.8400 - val_loss: 0.4304 - val_acc: 0.7933\n",
      "Epoch 195/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3818 - acc: 0.8371 - val_loss: 0.4251 - val_acc: 0.7867\n",
      "Epoch 196/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3985 - acc: 0.8171 - val_loss: 0.4246 - val_acc: 0.7867\n",
      "Epoch 197/500\n",
      "350/350 [==============================] - 0s 116us/step - loss: 0.3785 - acc: 0.8257 - val_loss: 0.4495 - val_acc: 0.7867\n",
      "Epoch 198/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3991 - acc: 0.8257 - val_loss: 0.5556 - val_acc: 0.7733\n",
      "Epoch 199/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.4097 - acc: 0.8086 - val_loss: 0.4260 - val_acc: 0.7933\n",
      "Epoch 200/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3846 - acc: 0.8314 - val_loss: 0.4232 - val_acc: 0.7933\n",
      "Epoch 201/500\n",
      "350/350 [==============================] - 0s 158us/step - loss: 0.3797 - acc: 0.8400 - val_loss: 0.4264 - val_acc: 0.7933\n",
      "Epoch 202/500\n",
      "350/350 [==============================] - 0s 164us/step - loss: 0.3756 - acc: 0.8257 - val_loss: 0.4551 - val_acc: 0.7933\n",
      "Epoch 203/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3970 - acc: 0.8114 - val_loss: 0.4272 - val_acc: 0.7800\n",
      "Epoch 204/500\n",
      "350/350 [==============================] - 0s 215us/step - loss: 0.3867 - acc: 0.8171 - val_loss: 0.4237 - val_acc: 0.7867\n",
      "Epoch 205/500\n",
      "350/350 [==============================] - 0s 185us/step - loss: 0.3792 - acc: 0.8343 - val_loss: 0.4283 - val_acc: 0.8000\n",
      "Epoch 206/500\n",
      "350/350 [==============================] - 0s 179us/step - loss: 0.3773 - acc: 0.8400 - val_loss: 0.4241 - val_acc: 0.8067\n",
      "Epoch 207/500\n",
      "350/350 [==============================] - 0s 192us/step - loss: 0.3746 - acc: 0.8314 - val_loss: 0.4860 - val_acc: 0.8000\n",
      "Epoch 208/500\n",
      "350/350 [==============================] - 0s 225us/step - loss: 0.4013 - acc: 0.8143 - val_loss: 0.4247 - val_acc: 0.7867\n",
      "Epoch 209/500\n",
      "350/350 [==============================] - 0s 205us/step - loss: 0.3857 - acc: 0.8286 - val_loss: 0.4293 - val_acc: 0.7933\n",
      "Epoch 210/500\n",
      "350/350 [==============================] - 0s 194us/step - loss: 0.3811 - acc: 0.8200 - val_loss: 0.4240 - val_acc: 0.8000\n",
      "Epoch 211/500\n",
      "350/350 [==============================] - 0s 216us/step - loss: 0.3909 - acc: 0.8171 - val_loss: 0.4406 - val_acc: 0.7867\n",
      "Epoch 212/500\n",
      "350/350 [==============================] - 0s 230us/step - loss: 0.3862 - acc: 0.8229 - val_loss: 0.4321 - val_acc: 0.7867\n",
      "Epoch 213/500\n",
      "350/350 [==============================] - 0s 166us/step - loss: 0.3797 - acc: 0.8457 - val_loss: 0.4316 - val_acc: 0.7933\n",
      "Epoch 214/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.3816 - acc: 0.8314 - val_loss: 0.4236 - val_acc: 0.7933\n",
      "Epoch 215/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3948 - acc: 0.8200 - val_loss: 0.4238 - val_acc: 0.7867\n",
      "Epoch 216/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3932 - acc: 0.8200 - val_loss: 0.4388 - val_acc: 0.7867\n",
      "Epoch 217/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3789 - acc: 0.8429 - val_loss: 0.4259 - val_acc: 0.8000\n",
      "Epoch 218/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.3910 - acc: 0.8171 - val_loss: 0.4318 - val_acc: 0.7933\n",
      "Epoch 219/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3907 - acc: 0.8343 - val_loss: 0.4333 - val_acc: 0.7600\n",
      "Epoch 220/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3923 - acc: 0.8171 - val_loss: 0.4382 - val_acc: 0.7867\n",
      "Epoch 221/500\n",
      "350/350 [==============================] - 0s 150us/step - loss: 0.3790 - acc: 0.8314 - val_loss: 0.4332 - val_acc: 0.7867\n",
      "Epoch 222/500\n",
      "350/350 [==============================] - 0s 149us/step - loss: 0.3783 - acc: 0.8371 - val_loss: 0.4266 - val_acc: 0.8067\n",
      "Epoch 223/500\n",
      "350/350 [==============================] - 0s 186us/step - loss: 0.3737 - acc: 0.8343 - val_loss: 0.4304 - val_acc: 0.8067\n",
      "Epoch 224/500\n",
      "350/350 [==============================] - 0s 185us/step - loss: 0.3920 - acc: 0.8343 - val_loss: 0.4259 - val_acc: 0.7800\n",
      "Epoch 225/500\n",
      "350/350 [==============================] - 0s 150us/step - loss: 0.3805 - acc: 0.8257 - val_loss: 0.4257 - val_acc: 0.7933\n",
      "Epoch 226/500\n",
      "350/350 [==============================] - 0s 163us/step - loss: 0.3860 - acc: 0.8286 - val_loss: 0.4245 - val_acc: 0.8000\n",
      "Epoch 227/500\n",
      "350/350 [==============================] - 0s 152us/step - loss: 0.3837 - acc: 0.8229 - val_loss: 0.4247 - val_acc: 0.8000\n",
      "Epoch 228/500\n",
      "350/350 [==============================] - 0s 177us/step - loss: 0.3793 - acc: 0.8343 - val_loss: 0.4511 - val_acc: 0.7800\n",
      "Epoch 229/500\n",
      "350/350 [==============================] - 0s 155us/step - loss: 0.3814 - acc: 0.8343 - val_loss: 0.4851 - val_acc: 0.7867\n",
      "Epoch 230/500\n",
      "350/350 [==============================] - 0s 183us/step - loss: 0.3711 - acc: 0.8543 - val_loss: 0.4351 - val_acc: 0.7667\n",
      "Epoch 231/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.3940 - acc: 0.8086 - val_loss: 0.4384 - val_acc: 0.7867\n",
      "Epoch 232/500\n",
      "350/350 [==============================] - 0s 149us/step - loss: 0.4066 - acc: 0.8343 - val_loss: 0.4245 - val_acc: 0.7867\n",
      "Epoch 233/500\n",
      "350/350 [==============================] - 0s 161us/step - loss: 0.3890 - acc: 0.8314 - val_loss: 0.4278 - val_acc: 0.7867\n",
      "Epoch 234/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.3779 - acc: 0.8257 - val_loss: 0.4242 - val_acc: 0.8067\n",
      "Epoch 235/500\n",
      "350/350 [==============================] - 0s 156us/step - loss: 0.3775 - acc: 0.8200 - val_loss: 0.4296 - val_acc: 0.7867\n",
      "Epoch 236/500\n",
      "350/350 [==============================] - 0s 176us/step - loss: 0.3825 - acc: 0.8371 - val_loss: 0.4304 - val_acc: 0.7933\n",
      "Epoch 237/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3838 - acc: 0.8200 - val_loss: 0.4268 - val_acc: 0.7867\n",
      "Epoch 238/500\n",
      "350/350 [==============================] - 0s 155us/step - loss: 0.3800 - acc: 0.8400 - val_loss: 0.4330 - val_acc: 0.7867\n",
      "Epoch 239/500\n",
      "350/350 [==============================] - 0s 163us/step - loss: 0.3784 - acc: 0.8286 - val_loss: 0.4311 - val_acc: 0.7933\n",
      "Epoch 240/500\n",
      "350/350 [==============================] - 0s 169us/step - loss: 0.3791 - acc: 0.8314 - val_loss: 0.4248 - val_acc: 0.7933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "350/350 [==============================] - 0s 191us/step - loss: 0.3826 - acc: 0.8229 - val_loss: 0.4769 - val_acc: 0.8000\n",
      "Epoch 242/500\n",
      "350/350 [==============================] - 0s 189us/step - loss: 0.3891 - acc: 0.8114 - val_loss: 0.4284 - val_acc: 0.8000\n",
      "Epoch 243/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.3914 - acc: 0.8229 - val_loss: 0.4271 - val_acc: 0.8000\n",
      "Epoch 244/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.3735 - acc: 0.8429 - val_loss: 0.4275 - val_acc: 0.8067\n",
      "Epoch 245/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.3830 - acc: 0.8200 - val_loss: 0.4256 - val_acc: 0.7800\n",
      "Epoch 246/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.3751 - acc: 0.8257 - val_loss: 0.4355 - val_acc: 0.7933\n",
      "Epoch 247/500\n",
      "350/350 [==============================] - 0s 163us/step - loss: 0.3779 - acc: 0.8343 - val_loss: 0.4418 - val_acc: 0.7733\n",
      "Epoch 248/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.3854 - acc: 0.8171 - val_loss: 0.4343 - val_acc: 0.8000\n",
      "Epoch 249/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3799 - acc: 0.8286 - val_loss: 0.4224 - val_acc: 0.7933\n",
      "Epoch 250/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.3850 - acc: 0.8200 - val_loss: 0.4413 - val_acc: 0.7533\n",
      "Epoch 251/500\n",
      "350/350 [==============================] - 0s 164us/step - loss: 0.3817 - acc: 0.8400 - val_loss: 0.4313 - val_acc: 0.7933\n",
      "Epoch 252/500\n",
      "350/350 [==============================] - 0s 171us/step - loss: 0.3860 - acc: 0.8343 - val_loss: 0.4280 - val_acc: 0.8000\n",
      "Epoch 253/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3827 - acc: 0.8343 - val_loss: 0.4342 - val_acc: 0.7867\n",
      "Epoch 254/500\n",
      "350/350 [==============================] - 0s 148us/step - loss: 0.3848 - acc: 0.8171 - val_loss: 0.4245 - val_acc: 0.7867\n",
      "Epoch 255/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3851 - acc: 0.8429 - val_loss: 0.4419 - val_acc: 0.7867\n",
      "Epoch 256/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.3987 - acc: 0.8086 - val_loss: 0.4748 - val_acc: 0.7867\n",
      "Epoch 257/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3899 - acc: 0.8229 - val_loss: 0.4369 - val_acc: 0.7867\n",
      "Epoch 258/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3778 - acc: 0.8400 - val_loss: 0.4782 - val_acc: 0.7867\n",
      "Epoch 259/500\n",
      "350/350 [==============================] - 0s 151us/step - loss: 0.3872 - acc: 0.8257 - val_loss: 0.4285 - val_acc: 0.7933\n",
      "Epoch 260/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3802 - acc: 0.8343 - val_loss: 0.4450 - val_acc: 0.7533\n",
      "Epoch 261/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3717 - acc: 0.8229 - val_loss: 0.4350 - val_acc: 0.7800\n",
      "Epoch 262/500\n",
      "350/350 [==============================] - 0s 156us/step - loss: 0.3800 - acc: 0.8286 - val_loss: 0.4423 - val_acc: 0.7800\n",
      "Epoch 263/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3758 - acc: 0.8314 - val_loss: 0.4241 - val_acc: 0.7933\n",
      "Epoch 264/500\n",
      "350/350 [==============================] - 0s 148us/step - loss: 0.3748 - acc: 0.8314 - val_loss: 0.4452 - val_acc: 0.7867\n",
      "Epoch 265/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.4094 - acc: 0.8029 - val_loss: 0.4466 - val_acc: 0.7533\n",
      "Epoch 266/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3929 - acc: 0.8029 - val_loss: 0.4381 - val_acc: 0.8000\n",
      "Epoch 267/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3792 - acc: 0.8343 - val_loss: 0.4228 - val_acc: 0.7867\n",
      "Epoch 268/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.3949 - acc: 0.8314 - val_loss: 0.4494 - val_acc: 0.7867\n",
      "Epoch 269/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.3963 - acc: 0.8286 - val_loss: 0.4281 - val_acc: 0.7933\n",
      "Epoch 270/500\n",
      "350/350 [==============================] - 0s 148us/step - loss: 0.3853 - acc: 0.8286 - val_loss: 0.4216 - val_acc: 0.7933\n",
      "Epoch 271/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3802 - acc: 0.8343 - val_loss: 0.4319 - val_acc: 0.7867\n",
      "Epoch 272/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3820 - acc: 0.8200 - val_loss: 0.4474 - val_acc: 0.7733\n",
      "Epoch 273/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3796 - acc: 0.8429 - val_loss: 0.4567 - val_acc: 0.7867\n",
      "Epoch 274/500\n",
      "350/350 [==============================] - 0s 198us/step - loss: 0.3793 - acc: 0.8257 - val_loss: 0.4322 - val_acc: 0.7933\n",
      "Epoch 275/500\n",
      "350/350 [==============================] - 0s 216us/step - loss: 0.3996 - acc: 0.8171 - val_loss: 0.4484 - val_acc: 0.7467\n",
      "Epoch 276/500\n",
      "350/350 [==============================] - 0s 225us/step - loss: 0.3829 - acc: 0.8457 - val_loss: 0.4346 - val_acc: 0.7867\n",
      "Epoch 277/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.3861 - acc: 0.8257 - val_loss: 0.4572 - val_acc: 0.7800\n",
      "Epoch 278/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3807 - acc: 0.8429 - val_loss: 0.4248 - val_acc: 0.7800\n",
      "Epoch 279/500\n",
      "350/350 [==============================] - 0s 155us/step - loss: 0.3813 - acc: 0.8229 - val_loss: 0.4271 - val_acc: 0.7800\n",
      "Epoch 280/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3762 - acc: 0.8400 - val_loss: 0.4351 - val_acc: 0.7800\n",
      "Epoch 281/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.3787 - acc: 0.8229 - val_loss: 0.4632 - val_acc: 0.7867\n",
      "Epoch 282/500\n",
      "350/350 [==============================] - 0s 160us/step - loss: 0.3970 - acc: 0.8286 - val_loss: 0.4252 - val_acc: 0.7867\n",
      "Epoch 283/500\n",
      "350/350 [==============================] - 0s 159us/step - loss: 0.3772 - acc: 0.8429 - val_loss: 0.4285 - val_acc: 0.7800\n",
      "Epoch 284/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3776 - acc: 0.8371 - val_loss: 0.4268 - val_acc: 0.7800\n",
      "Epoch 285/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3811 - acc: 0.8314 - val_loss: 0.4268 - val_acc: 0.7800\n",
      "Epoch 286/500\n",
      "350/350 [==============================] - 0s 157us/step - loss: 0.3772 - acc: 0.8343 - val_loss: 0.4276 - val_acc: 0.7867\n",
      "Epoch 287/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.3757 - acc: 0.8200 - val_loss: 0.4244 - val_acc: 0.7933\n",
      "Epoch 288/500\n",
      "350/350 [==============================] - 0s 160us/step - loss: 0.3789 - acc: 0.8457 - val_loss: 0.4243 - val_acc: 0.7867\n",
      "Epoch 289/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3758 - acc: 0.8429 - val_loss: 0.4272 - val_acc: 0.8067\n",
      "Epoch 290/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3734 - acc: 0.8257 - val_loss: 0.4455 - val_acc: 0.7733\n",
      "Epoch 291/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.3853 - acc: 0.8314 - val_loss: 0.4244 - val_acc: 0.8000\n",
      "Epoch 292/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3764 - acc: 0.8343 - val_loss: 0.4224 - val_acc: 0.7933\n",
      "Epoch 293/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3731 - acc: 0.8229 - val_loss: 0.4361 - val_acc: 0.7800\n",
      "Epoch 294/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3837 - acc: 0.8257 - val_loss: 0.4431 - val_acc: 0.7867\n",
      "Epoch 295/500\n",
      "350/350 [==============================] - 0s 152us/step - loss: 0.3741 - acc: 0.8400 - val_loss: 0.4336 - val_acc: 0.7867\n",
      "Epoch 296/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.3738 - acc: 0.8343 - val_loss: 0.4636 - val_acc: 0.7467\n",
      "Epoch 297/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.3835 - acc: 0.8171 - val_loss: 0.4363 - val_acc: 0.7667\n",
      "Epoch 298/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.3872 - acc: 0.8114 - val_loss: 0.4437 - val_acc: 0.7867\n",
      "Epoch 299/500\n",
      "350/350 [==============================] - 0s 159us/step - loss: 0.3793 - acc: 0.8514 - val_loss: 0.4539 - val_acc: 0.7867\n",
      "Epoch 300/500\n",
      "350/350 [==============================] - 0s 181us/step - loss: 0.4079 - acc: 0.8086 - val_loss: 0.4286 - val_acc: 0.7933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "350/350 [==============================] - 0s 149us/step - loss: 0.3730 - acc: 0.8457 - val_loss: 0.4238 - val_acc: 0.7933\n",
      "Epoch 302/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3794 - acc: 0.8314 - val_loss: 0.4278 - val_acc: 0.7800\n",
      "Epoch 303/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3796 - acc: 0.8429 - val_loss: 0.4328 - val_acc: 0.7867\n",
      "Epoch 304/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3710 - acc: 0.8400 - val_loss: 0.4371 - val_acc: 0.7867\n",
      "Epoch 305/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3763 - acc: 0.8229 - val_loss: 0.4296 - val_acc: 0.7867\n",
      "Epoch 306/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3865 - acc: 0.8143 - val_loss: 0.4219 - val_acc: 0.7933\n",
      "Epoch 307/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3794 - acc: 0.8086 - val_loss: 0.4499 - val_acc: 0.7800\n",
      "Epoch 308/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3915 - acc: 0.8143 - val_loss: 0.4229 - val_acc: 0.8000\n",
      "Epoch 309/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3738 - acc: 0.8371 - val_loss: 0.4550 - val_acc: 0.7800\n",
      "Epoch 310/500\n",
      "350/350 [==============================] - 0s 123us/step - loss: 0.3724 - acc: 0.8400 - val_loss: 0.4444 - val_acc: 0.7867\n",
      "Epoch 311/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3782 - acc: 0.8286 - val_loss: 0.4820 - val_acc: 0.7800\n",
      "Epoch 312/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3940 - acc: 0.7914 - val_loss: 0.4692 - val_acc: 0.7800\n",
      "Epoch 313/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3799 - acc: 0.8400 - val_loss: 0.4356 - val_acc: 0.7867\n",
      "Epoch 314/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3800 - acc: 0.8371 - val_loss: 0.4518 - val_acc: 0.7800\n",
      "Epoch 315/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.3780 - acc: 0.8257 - val_loss: 0.4257 - val_acc: 0.7933\n",
      "Epoch 316/500\n",
      "350/350 [==============================] - 0s 160us/step - loss: 0.3773 - acc: 0.8429 - val_loss: 0.4469 - val_acc: 0.7467\n",
      "Epoch 317/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3862 - acc: 0.8429 - val_loss: 0.4269 - val_acc: 0.7800\n",
      "Epoch 318/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.3834 - acc: 0.8429 - val_loss: 0.4237 - val_acc: 0.7867\n",
      "Epoch 319/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3806 - acc: 0.8400 - val_loss: 0.4314 - val_acc: 0.7800\n",
      "Epoch 320/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3930 - acc: 0.8029 - val_loss: 0.4228 - val_acc: 0.7800\n",
      "Epoch 321/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3711 - acc: 0.8400 - val_loss: 0.4267 - val_acc: 0.8000\n",
      "Epoch 322/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.3903 - acc: 0.8171 - val_loss: 0.4390 - val_acc: 0.7933\n",
      "Epoch 323/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.3777 - acc: 0.8257 - val_loss: 0.4243 - val_acc: 0.7867\n",
      "Epoch 324/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.3831 - acc: 0.8286 - val_loss: 0.4266 - val_acc: 0.8000\n",
      "Epoch 325/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3864 - acc: 0.8229 - val_loss: 0.4215 - val_acc: 0.7933\n",
      "Epoch 326/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3740 - acc: 0.8457 - val_loss: 0.4634 - val_acc: 0.7867\n",
      "Epoch 327/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.3982 - acc: 0.8057 - val_loss: 0.4260 - val_acc: 0.8000\n",
      "Epoch 328/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3865 - acc: 0.8286 - val_loss: 0.4483 - val_acc: 0.7800\n",
      "Epoch 329/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3848 - acc: 0.8343 - val_loss: 0.4412 - val_acc: 0.7867\n",
      "Epoch 330/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.3723 - acc: 0.8429 - val_loss: 0.4252 - val_acc: 0.7867\n",
      "Epoch 331/500\n",
      "350/350 [==============================] - 0s 161us/step - loss: 0.3826 - acc: 0.8343 - val_loss: 0.4236 - val_acc: 0.7800\n",
      "Epoch 332/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.3746 - acc: 0.8343 - val_loss: 0.4231 - val_acc: 0.7867\n",
      "Epoch 333/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3720 - acc: 0.8400 - val_loss: 0.4328 - val_acc: 0.7733\n",
      "Epoch 334/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.3759 - acc: 0.8400 - val_loss: 0.4536 - val_acc: 0.7800\n",
      "Epoch 335/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3754 - acc: 0.8286 - val_loss: 0.4228 - val_acc: 0.7933\n",
      "Epoch 336/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3719 - acc: 0.8286 - val_loss: 0.4263 - val_acc: 0.7867\n",
      "Epoch 337/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3793 - acc: 0.8229 - val_loss: 0.4343 - val_acc: 0.7867\n",
      "Epoch 338/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3748 - acc: 0.8343 - val_loss: 0.4302 - val_acc: 0.7933\n",
      "Epoch 339/500\n",
      "350/350 [==============================] - 0s 145us/step - loss: 0.3780 - acc: 0.8286 - val_loss: 0.4814 - val_acc: 0.7933\n",
      "Epoch 340/500\n",
      "350/350 [==============================] - 0s 185us/step - loss: 0.3812 - acc: 0.8314 - val_loss: 0.4333 - val_acc: 0.7800\n",
      "Epoch 341/500\n",
      "350/350 [==============================] - 0s 211us/step - loss: 0.3756 - acc: 0.8429 - val_loss: 0.4202 - val_acc: 0.7933\n",
      "Epoch 342/500\n",
      "350/350 [==============================] - 0s 216us/step - loss: 0.3710 - acc: 0.8286 - val_loss: 0.4218 - val_acc: 0.7867\n",
      "Epoch 343/500\n",
      "350/350 [==============================] - 0s 183us/step - loss: 0.3704 - acc: 0.8429 - val_loss: 0.4344 - val_acc: 0.7867\n",
      "Epoch 344/500\n",
      "350/350 [==============================] - 0s 212us/step - loss: 0.3873 - acc: 0.8257 - val_loss: 0.4224 - val_acc: 0.7933\n",
      "Epoch 345/500\n",
      "350/350 [==============================] - 0s 186us/step - loss: 0.3761 - acc: 0.8371 - val_loss: 0.4301 - val_acc: 0.7800\n",
      "Epoch 346/500\n",
      "350/350 [==============================] - 0s 163us/step - loss: 0.3847 - acc: 0.8286 - val_loss: 0.5192 - val_acc: 0.7867\n",
      "Epoch 347/500\n",
      "350/350 [==============================] - 0s 175us/step - loss: 0.4160 - acc: 0.8029 - val_loss: 0.4338 - val_acc: 0.7800\n",
      "Epoch 348/500\n",
      "350/350 [==============================] - 0s 169us/step - loss: 0.4008 - acc: 0.8057 - val_loss: 0.4323 - val_acc: 0.7733\n",
      "Epoch 349/500\n",
      "350/350 [==============================] - 0s 190us/step - loss: 0.4157 - acc: 0.8200 - val_loss: 0.4893 - val_acc: 0.7867\n",
      "Epoch 350/500\n",
      "350/350 [==============================] - 0s 155us/step - loss: 0.3916 - acc: 0.8314 - val_loss: 0.4349 - val_acc: 0.7867\n",
      "Epoch 351/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.3774 - acc: 0.8314 - val_loss: 0.4549 - val_acc: 0.7933\n",
      "Epoch 352/500\n",
      "350/350 [==============================] - 0s 162us/step - loss: 0.3701 - acc: 0.8400 - val_loss: 0.4357 - val_acc: 0.7733\n",
      "Epoch 353/500\n",
      "350/350 [==============================] - 0s 159us/step - loss: 0.3780 - acc: 0.8286 - val_loss: 0.4376 - val_acc: 0.7733\n",
      "Epoch 354/500\n",
      "350/350 [==============================] - 0s 193us/step - loss: 0.3904 - acc: 0.8400 - val_loss: 0.4339 - val_acc: 0.7867\n",
      "Epoch 355/500\n",
      "350/350 [==============================] - 0s 201us/step - loss: 0.3946 - acc: 0.8229 - val_loss: 0.4215 - val_acc: 0.7800\n",
      "Epoch 356/500\n",
      "350/350 [==============================] - 0s 184us/step - loss: 0.3738 - acc: 0.8343 - val_loss: 0.4231 - val_acc: 0.7933\n",
      "Epoch 357/500\n",
      "350/350 [==============================] - 0s 168us/step - loss: 0.3721 - acc: 0.8286 - val_loss: 0.4262 - val_acc: 0.8000\n",
      "Epoch 358/500\n",
      "350/350 [==============================] - 0s 157us/step - loss: 0.3741 - acc: 0.8200 - val_loss: 0.4283 - val_acc: 0.8000\n",
      "Epoch 359/500\n",
      "350/350 [==============================] - 0s 178us/step - loss: 0.3676 - acc: 0.8571 - val_loss: 0.4225 - val_acc: 0.7933\n",
      "Epoch 360/500\n",
      "350/350 [==============================] - 0s 162us/step - loss: 0.3878 - acc: 0.8229 - val_loss: 0.4266 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3805 - acc: 0.8200 - val_loss: 0.4503 - val_acc: 0.7867\n",
      "Epoch 362/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3831 - acc: 0.8429 - val_loss: 0.4400 - val_acc: 0.7467\n",
      "Epoch 363/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.3902 - acc: 0.8429 - val_loss: 0.4210 - val_acc: 0.7933\n",
      "Epoch 364/500\n",
      "350/350 [==============================] - 0s 161us/step - loss: 0.3781 - acc: 0.8371 - val_loss: 0.4248 - val_acc: 0.8000\n",
      "Epoch 365/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3775 - acc: 0.8229 - val_loss: 0.4240 - val_acc: 0.8000\n",
      "Epoch 366/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.3815 - acc: 0.8257 - val_loss: 0.4228 - val_acc: 0.8000\n",
      "Epoch 367/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3781 - acc: 0.8257 - val_loss: 0.4229 - val_acc: 0.7867\n",
      "Epoch 368/500\n",
      "350/350 [==============================] - 0s 162us/step - loss: 0.3748 - acc: 0.8371 - val_loss: 0.4313 - val_acc: 0.7800\n",
      "Epoch 369/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.3723 - acc: 0.8543 - val_loss: 0.4227 - val_acc: 0.7867\n",
      "Epoch 370/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3636 - acc: 0.8371 - val_loss: 0.4927 - val_acc: 0.7800\n",
      "Epoch 371/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.3821 - acc: 0.8286 - val_loss: 0.4458 - val_acc: 0.7933\n",
      "Epoch 372/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3819 - acc: 0.8343 - val_loss: 0.4252 - val_acc: 0.8067\n",
      "Epoch 373/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.3750 - acc: 0.8257 - val_loss: 0.4485 - val_acc: 0.7867\n",
      "Epoch 374/500\n",
      "350/350 [==============================] - 0s 202us/step - loss: 0.3839 - acc: 0.8143 - val_loss: 0.4702 - val_acc: 0.7933\n",
      "Epoch 375/500\n",
      "350/350 [==============================] - 0s 149us/step - loss: 0.3828 - acc: 0.8257 - val_loss: 0.4219 - val_acc: 0.7867\n",
      "Epoch 376/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.3775 - acc: 0.8514 - val_loss: 0.4261 - val_acc: 0.7867\n",
      "Epoch 377/500\n",
      "350/350 [==============================] - 0s 151us/step - loss: 0.3762 - acc: 0.8371 - val_loss: 0.4344 - val_acc: 0.7800\n",
      "Epoch 378/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3729 - acc: 0.8486 - val_loss: 0.4294 - val_acc: 0.7867\n",
      "Epoch 379/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3819 - acc: 0.8343 - val_loss: 0.4249 - val_acc: 0.8067\n",
      "Epoch 380/500\n",
      "350/350 [==============================] - 0s 153us/step - loss: 0.3862 - acc: 0.8229 - val_loss: 0.4555 - val_acc: 0.7867\n",
      "Epoch 381/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.4041 - acc: 0.8171 - val_loss: 0.4242 - val_acc: 0.8067\n",
      "Epoch 382/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3859 - acc: 0.8171 - val_loss: 0.4293 - val_acc: 0.8000\n",
      "Epoch 383/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3718 - acc: 0.8429 - val_loss: 0.4223 - val_acc: 0.7933\n",
      "Epoch 384/500\n",
      "350/350 [==============================] - 0s 103us/step - loss: 0.3769 - acc: 0.8343 - val_loss: 0.4234 - val_acc: 0.8000\n",
      "Epoch 385/500\n",
      "350/350 [==============================] - 0s 123us/step - loss: 0.3829 - acc: 0.8371 - val_loss: 0.4514 - val_acc: 0.7933\n",
      "Epoch 386/500\n",
      "350/350 [==============================] - 0s 114us/step - loss: 0.3777 - acc: 0.8486 - val_loss: 0.4355 - val_acc: 0.7800\n",
      "Epoch 387/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.3794 - acc: 0.8371 - val_loss: 0.4749 - val_acc: 0.7867\n",
      "Epoch 388/500\n",
      "350/350 [==============================] - 0s 119us/step - loss: 0.3841 - acc: 0.8257 - val_loss: 0.4519 - val_acc: 0.7867\n",
      "Epoch 389/500\n",
      "350/350 [==============================] - 0s 107us/step - loss: 0.3815 - acc: 0.8314 - val_loss: 0.4371 - val_acc: 0.7733\n",
      "Epoch 390/500\n",
      "350/350 [==============================] - 0s 195us/step - loss: 0.3835 - acc: 0.8429 - val_loss: 0.4208 - val_acc: 0.7867\n",
      "Epoch 391/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.4006 - acc: 0.8171 - val_loss: 0.4423 - val_acc: 0.7733\n",
      "Epoch 392/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3745 - acc: 0.8343 - val_loss: 0.4276 - val_acc: 0.7933\n",
      "Epoch 393/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3792 - acc: 0.8429 - val_loss: 0.4466 - val_acc: 0.7867\n",
      "Epoch 394/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3742 - acc: 0.8429 - val_loss: 0.4305 - val_acc: 0.7933\n",
      "Epoch 395/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.3680 - acc: 0.8429 - val_loss: 0.4214 - val_acc: 0.7933\n",
      "Epoch 396/500\n",
      "350/350 [==============================] - 0s 159us/step - loss: 0.3828 - acc: 0.8229 - val_loss: 0.4369 - val_acc: 0.7800\n",
      "Epoch 397/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.3786 - acc: 0.8229 - val_loss: 0.4231 - val_acc: 0.7933\n",
      "Epoch 398/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.3788 - acc: 0.8171 - val_loss: 0.4400 - val_acc: 0.7867\n",
      "Epoch 399/500\n",
      "350/350 [==============================] - 0s 178us/step - loss: 0.3715 - acc: 0.8457 - val_loss: 0.4244 - val_acc: 0.7867\n",
      "Epoch 400/500\n",
      "350/350 [==============================] - 0s 171us/step - loss: 0.3863 - acc: 0.8200 - val_loss: 0.4224 - val_acc: 0.7933\n",
      "Epoch 401/500\n",
      "350/350 [==============================] - 0s 157us/step - loss: 0.3778 - acc: 0.8371 - val_loss: 0.4223 - val_acc: 0.7800\n",
      "Epoch 402/500\n",
      "350/350 [==============================] - 0s 149us/step - loss: 0.3768 - acc: 0.8286 - val_loss: 0.4209 - val_acc: 0.7867\n",
      "Epoch 403/500\n",
      "350/350 [==============================] - 0s 160us/step - loss: 0.3651 - acc: 0.8400 - val_loss: 0.4873 - val_acc: 0.7933\n",
      "Epoch 404/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.4023 - acc: 0.8143 - val_loss: 0.4736 - val_acc: 0.7867\n",
      "Epoch 405/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3800 - acc: 0.8514 - val_loss: 0.4530 - val_acc: 0.7933\n",
      "Epoch 406/500\n",
      "350/350 [==============================] - 0s 159us/step - loss: 0.3697 - acc: 0.8429 - val_loss: 0.4230 - val_acc: 0.8000\n",
      "Epoch 407/500\n",
      "350/350 [==============================] - 0s 164us/step - loss: 0.3733 - acc: 0.8429 - val_loss: 0.4238 - val_acc: 0.7867\n",
      "Epoch 408/500\n",
      "350/350 [==============================] - 0s 152us/step - loss: 0.3830 - acc: 0.8343 - val_loss: 0.4923 - val_acc: 0.7933\n",
      "Epoch 409/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3813 - acc: 0.8371 - val_loss: 0.4219 - val_acc: 0.8000\n",
      "Epoch 410/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.3754 - acc: 0.8314 - val_loss: 0.4255 - val_acc: 0.7800\n",
      "Epoch 411/500\n",
      "350/350 [==============================] - 0s 156us/step - loss: 0.3816 - acc: 0.8257 - val_loss: 0.4239 - val_acc: 0.8067\n",
      "Epoch 412/500\n",
      "350/350 [==============================] - 0s 151us/step - loss: 0.3793 - acc: 0.8086 - val_loss: 0.4488 - val_acc: 0.7467\n",
      "Epoch 413/500\n",
      "350/350 [==============================] - 0s 174us/step - loss: 0.3849 - acc: 0.8229 - val_loss: 0.4233 - val_acc: 0.7933\n",
      "Epoch 414/500\n",
      "350/350 [==============================] - 0s 149us/step - loss: 0.3729 - acc: 0.8314 - val_loss: 0.4279 - val_acc: 0.7933\n",
      "Epoch 415/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.3738 - acc: 0.8286 - val_loss: 0.4904 - val_acc: 0.7933\n",
      "Epoch 416/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.3791 - acc: 0.8343 - val_loss: 0.4579 - val_acc: 0.7600\n",
      "Epoch 417/500\n",
      "350/350 [==============================] - 0s 161us/step - loss: 0.3700 - acc: 0.8371 - val_loss: 0.4448 - val_acc: 0.7867\n",
      "Epoch 418/500\n",
      "350/350 [==============================] - 0s 161us/step - loss: 0.3799 - acc: 0.8371 - val_loss: 0.4840 - val_acc: 0.7933\n",
      "Epoch 419/500\n",
      "350/350 [==============================] - 0s 157us/step - loss: 0.3817 - acc: 0.8286 - val_loss: 0.4213 - val_acc: 0.7933\n",
      "Epoch 420/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3737 - acc: 0.8229 - val_loss: 0.4245 - val_acc: 0.7933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "350/350 [==============================] - 0s 130us/step - loss: 0.3777 - acc: 0.8229 - val_loss: 0.4336 - val_acc: 0.7933\n",
      "Epoch 422/500\n",
      "350/350 [==============================] - 0s 128us/step - loss: 0.3770 - acc: 0.8371 - val_loss: 0.4225 - val_acc: 0.7933\n",
      "Epoch 423/500\n",
      "350/350 [==============================] - 0s 150us/step - loss: 0.3857 - acc: 0.8143 - val_loss: 0.4954 - val_acc: 0.7867\n",
      "Epoch 424/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3708 - acc: 0.8486 - val_loss: 0.4253 - val_acc: 0.8000\n",
      "Epoch 425/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.3756 - acc: 0.8343 - val_loss: 0.5034 - val_acc: 0.7800\n",
      "Epoch 426/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3784 - acc: 0.8229 - val_loss: 0.4250 - val_acc: 0.8000\n",
      "Epoch 427/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.3725 - acc: 0.8486 - val_loss: 0.4253 - val_acc: 0.8000\n",
      "Epoch 428/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3655 - acc: 0.8286 - val_loss: 0.4585 - val_acc: 0.7867\n",
      "Epoch 429/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3736 - acc: 0.8286 - val_loss: 0.4758 - val_acc: 0.7867\n",
      "Epoch 430/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3808 - acc: 0.8314 - val_loss: 0.4242 - val_acc: 0.7867\n",
      "Epoch 431/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.3881 - acc: 0.8257 - val_loss: 0.4221 - val_acc: 0.7800\n",
      "Epoch 432/500\n",
      "350/350 [==============================] - 0s 123us/step - loss: 0.3727 - acc: 0.8400 - val_loss: 0.4307 - val_acc: 0.7933\n",
      "Epoch 433/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3778 - acc: 0.8457 - val_loss: 0.4300 - val_acc: 0.7867\n",
      "Epoch 434/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3722 - acc: 0.8371 - val_loss: 0.4696 - val_acc: 0.7867\n",
      "Epoch 435/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3738 - acc: 0.8486 - val_loss: 0.4228 - val_acc: 0.7933\n",
      "Epoch 436/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.3797 - acc: 0.8257 - val_loss: 0.4408 - val_acc: 0.7733\n",
      "Epoch 437/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3764 - acc: 0.8486 - val_loss: 0.4353 - val_acc: 0.7933\n",
      "Epoch 438/500\n",
      "350/350 [==============================] - 0s 118us/step - loss: 0.3764 - acc: 0.8400 - val_loss: 0.4303 - val_acc: 0.7800\n",
      "Epoch 439/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3773 - acc: 0.8429 - val_loss: 0.4213 - val_acc: 0.7800\n",
      "Epoch 440/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3891 - acc: 0.8371 - val_loss: 0.4465 - val_acc: 0.7733\n",
      "Epoch 441/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3874 - acc: 0.8429 - val_loss: 0.4285 - val_acc: 0.7933\n",
      "Epoch 442/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3891 - acc: 0.8343 - val_loss: 0.4349 - val_acc: 0.7333\n",
      "Epoch 443/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3733 - acc: 0.8514 - val_loss: 0.4554 - val_acc: 0.7867\n",
      "Epoch 444/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3725 - acc: 0.8286 - val_loss: 0.5019 - val_acc: 0.7867\n",
      "Epoch 445/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.3757 - acc: 0.8229 - val_loss: 0.4229 - val_acc: 0.7933\n",
      "Epoch 446/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3779 - acc: 0.8314 - val_loss: 0.4256 - val_acc: 0.7800\n",
      "Epoch 447/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3732 - acc: 0.8200 - val_loss: 0.4801 - val_acc: 0.7867\n",
      "Epoch 448/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3734 - acc: 0.8371 - val_loss: 0.4841 - val_acc: 0.7867\n",
      "Epoch 449/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3942 - acc: 0.8257 - val_loss: 0.4235 - val_acc: 0.8067\n",
      "Epoch 450/500\n",
      "350/350 [==============================] - 0s 150us/step - loss: 0.3816 - acc: 0.8286 - val_loss: 0.4223 - val_acc: 0.8000\n",
      "Epoch 451/500\n",
      "350/350 [==============================] - 0s 125us/step - loss: 0.3677 - acc: 0.8257 - val_loss: 0.4440 - val_acc: 0.7733\n",
      "Epoch 452/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3860 - acc: 0.8429 - val_loss: 0.4418 - val_acc: 0.7733\n",
      "Epoch 453/500\n",
      "350/350 [==============================] - 0s 140us/step - loss: 0.3657 - acc: 0.8314 - val_loss: 0.4200 - val_acc: 0.7933\n",
      "Epoch 454/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.3748 - acc: 0.8257 - val_loss: 0.4246 - val_acc: 0.8000\n",
      "Epoch 455/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3770 - acc: 0.8371 - val_loss: 0.4288 - val_acc: 0.8000\n",
      "Epoch 456/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.3604 - acc: 0.8429 - val_loss: 0.4294 - val_acc: 0.7933\n",
      "Epoch 457/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3730 - acc: 0.8171 - val_loss: 0.4318 - val_acc: 0.7933\n",
      "Epoch 458/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3779 - acc: 0.8400 - val_loss: 0.4239 - val_acc: 0.8067\n",
      "Epoch 459/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3721 - acc: 0.8486 - val_loss: 0.4268 - val_acc: 0.7867\n",
      "Epoch 460/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3782 - acc: 0.8200 - val_loss: 0.4328 - val_acc: 0.7867\n",
      "Epoch 461/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.3890 - acc: 0.8371 - val_loss: 0.4330 - val_acc: 0.7933\n",
      "Epoch 462/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3632 - acc: 0.8343 - val_loss: 0.4485 - val_acc: 0.7533\n",
      "Epoch 463/500\n",
      "350/350 [==============================] - 0s 126us/step - loss: 0.3787 - acc: 0.8229 - val_loss: 0.4254 - val_acc: 0.8133\n",
      "Epoch 464/500\n",
      "350/350 [==============================] - 0s 136us/step - loss: 0.3658 - acc: 0.8257 - val_loss: 0.4395 - val_acc: 0.7733\n",
      "Epoch 465/500\n",
      "350/350 [==============================] - 0s 138us/step - loss: 0.3679 - acc: 0.8343 - val_loss: 0.4243 - val_acc: 0.7933\n",
      "Epoch 466/500\n",
      "350/350 [==============================] - 0s 139us/step - loss: 0.3691 - acc: 0.8314 - val_loss: 0.4438 - val_acc: 0.7800\n",
      "Epoch 467/500\n",
      "350/350 [==============================] - 0s 147us/step - loss: 0.3837 - acc: 0.8343 - val_loss: 0.4323 - val_acc: 0.7933\n",
      "Epoch 468/500\n",
      "350/350 [==============================] - 0s 152us/step - loss: 0.3688 - acc: 0.8400 - val_loss: 0.4311 - val_acc: 0.8000\n",
      "Epoch 469/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.3741 - acc: 0.8543 - val_loss: 0.4246 - val_acc: 0.7867\n",
      "Epoch 470/500\n",
      "350/350 [==============================] - 0s 154us/step - loss: 0.3760 - acc: 0.8257 - val_loss: 0.4381 - val_acc: 0.7733\n",
      "Epoch 471/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.3680 - acc: 0.8457 - val_loss: 0.4296 - val_acc: 0.7933\n",
      "Epoch 472/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3729 - acc: 0.8314 - val_loss: 0.4231 - val_acc: 0.7867\n",
      "Epoch 473/500\n",
      "350/350 [==============================] - 0s 141us/step - loss: 0.3837 - acc: 0.8229 - val_loss: 0.4237 - val_acc: 0.8067\n",
      "Epoch 474/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3750 - acc: 0.8229 - val_loss: 0.4874 - val_acc: 0.7800\n",
      "Epoch 475/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.3785 - acc: 0.8257 - val_loss: 0.4285 - val_acc: 0.7867\n",
      "Epoch 476/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3717 - acc: 0.8400 - val_loss: 0.4259 - val_acc: 0.7933\n",
      "Epoch 477/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.3685 - acc: 0.8486 - val_loss: 0.4233 - val_acc: 0.7800\n",
      "Epoch 478/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.3749 - acc: 0.8371 - val_loss: 0.4622 - val_acc: 0.7867\n",
      "Epoch 479/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3846 - acc: 0.8257 - val_loss: 0.4818 - val_acc: 0.7867\n",
      "Epoch 480/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3729 - acc: 0.8400 - val_loss: 0.4357 - val_acc: 0.7800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.3797 - acc: 0.8429 - val_loss: 0.4263 - val_acc: 0.7933\n",
      "Epoch 482/500\n",
      "350/350 [==============================] - 0s 144us/step - loss: 0.3737 - acc: 0.8257 - val_loss: 0.4270 - val_acc: 0.7933\n",
      "Epoch 483/500\n",
      "350/350 [==============================] - 0s 124us/step - loss: 0.3741 - acc: 0.8486 - val_loss: 0.4256 - val_acc: 0.7933\n",
      "Epoch 484/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.3682 - acc: 0.8429 - val_loss: 0.4323 - val_acc: 0.7733\n",
      "Epoch 485/500\n",
      "350/350 [==============================] - 0s 129us/step - loss: 0.3639 - acc: 0.8514 - val_loss: 0.4404 - val_acc: 0.7733\n",
      "Epoch 486/500\n",
      "350/350 [==============================] - 0s 133us/step - loss: 0.3959 - acc: 0.8057 - val_loss: 0.4476 - val_acc: 0.7733\n",
      "Epoch 487/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3726 - acc: 0.8314 - val_loss: 0.4621 - val_acc: 0.7933\n",
      "Epoch 488/500\n",
      "350/350 [==============================] - 0s 132us/step - loss: 0.3748 - acc: 0.8257 - val_loss: 0.4413 - val_acc: 0.7800\n",
      "Epoch 489/500\n",
      "350/350 [==============================] - 0s 120us/step - loss: 0.3833 - acc: 0.8371 - val_loss: 0.4348 - val_acc: 0.7933\n",
      "Epoch 490/500\n",
      "350/350 [==============================] - 0s 131us/step - loss: 0.3704 - acc: 0.8343 - val_loss: 0.4352 - val_acc: 0.7800\n",
      "Epoch 491/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3694 - acc: 0.8429 - val_loss: 0.4822 - val_acc: 0.7867\n",
      "Epoch 492/500\n",
      "350/350 [==============================] - 0s 137us/step - loss: 0.3955 - acc: 0.8314 - val_loss: 0.4258 - val_acc: 0.7800\n",
      "Epoch 493/500\n",
      "350/350 [==============================] - 0s 142us/step - loss: 0.3925 - acc: 0.8229 - val_loss: 0.4245 - val_acc: 0.8000\n",
      "Epoch 494/500\n",
      "350/350 [==============================] - 0s 135us/step - loss: 0.3726 - acc: 0.8457 - val_loss: 0.4226 - val_acc: 0.7933\n",
      "Epoch 495/500\n",
      "350/350 [==============================] - 0s 146us/step - loss: 0.3781 - acc: 0.8314 - val_loss: 0.4353 - val_acc: 0.7867\n",
      "Epoch 496/500\n",
      "350/350 [==============================] - 0s 127us/step - loss: 0.3852 - acc: 0.8257 - val_loss: 0.4213 - val_acc: 0.7867\n",
      "Epoch 497/500\n",
      "350/350 [==============================] - 0s 122us/step - loss: 0.3837 - acc: 0.8286 - val_loss: 0.4263 - val_acc: 0.7933\n",
      "Epoch 498/500\n",
      "350/350 [==============================] - 0s 121us/step - loss: 0.3635 - acc: 0.8371 - val_loss: 0.4737 - val_acc: 0.7733\n",
      "Epoch 499/500\n",
      "350/350 [==============================] - 0s 143us/step - loss: 0.3672 - acc: 0.8429 - val_loss: 0.4209 - val_acc: 0.7867\n",
      "Epoch 500/500\n",
      "350/350 [==============================] - 0s 134us/step - loss: 0.3881 - acc: 0.8314 - val_loss: 0.4210 - val_acc: 0.7867\n"
     ]
    }
   ],
   "source": [
    "var = classifier.fit(X_train,y_train, batch_size=10, epochs=500, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Treino')\n",
    "plt.grid(True)\n",
    "plt.plot(var.history['acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Teste')\n",
    "plt.grid(True)\n",
    "plt.plot(var.history['val_acc'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
